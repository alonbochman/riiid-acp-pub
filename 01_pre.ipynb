{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Added cell to measure execution time\r\n",
        "import time\r\n",
        "start_time = time.time()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638215848635
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import enum\n",
        "\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from pathlib import Path\n",
        "from scipy.sparse import coo_matrix, dok_matrix, lil_matrix, csr_matrix, bsr_matrix\n",
        "from tqdm import tqdm"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1638215849378
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input path\n",
        "Set this to the location of input .csv files"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "in_d = Path('../input')"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1638215849881
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To line-profile a function:\n",
        "\n",
        "```\n",
        "conda install -c anaconda line_profiler\n",
        "```\n",
        "\n",
        "Then run:\n",
        "\n",
        "```\n",
        "%lprun -f f1 f2(...)\n",
        "```\n",
        "\n",
        "Both functions `f1` and `f2` can be the same or different ie. your code starts at `f2` but you are only interested in profiling `f1`\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Execution time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "--- Execution time: 1.515367031097412 seconds ---\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638215850758
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class _H:\n",
        "    '''Hyperparams'''\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__ = kwargs\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.__dict__)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1638215851572
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H = _H(\n",
        "    version = '210101b',\n",
        "    max_users = 450000,\n",
        "    max_questions = 13523,\n",
        "    valid_pct = 0.025, # ~2.5M rows\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1638215852500
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpers"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize(df, cols):\n",
        "    cats_d = {}\n",
        "    for col in cols:\n",
        "        if df[col].dtype.name == 'category':\n",
        "            print(f'{col} already categorized')\n",
        "        else:\n",
        "            df[col] = pd.Categorical(df[col])\n",
        "        cats_d[col] = df[col].cat.categories.values\n",
        "    return cats_d"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1638215853246
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def means_stds(df, cols):\n",
        "    return { col: df[col].mean() for col in cols }, { col: df[col].std() for col in cols }"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1638215854222
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "question_dtypes = {\n",
        "    'question_id': 'int16',\n",
        "    'bundle_id': 'int16',\n",
        "    'correct_answer': 'int8',\n",
        "    'part': 'int8',\n",
        "    'tags': 'object',\n",
        "}\n",
        "\n",
        "questions_df = pd.read_csv(\n",
        "    in_d / 'questions.csv',\n",
        "    usecols=question_dtypes.keys(),\n",
        "    dtype=question_dtypes,\n",
        ")\n",
        "\n",
        "qcats = categorize(questions_df, ['question_id', 'bundle_id', 'correct_answer', 'part'])\n",
        "qcats"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "{'question_id': array([    0,     1,     2, ..., 13520, 13521, 13522]),\n 'bundle_id': array([    0,     1,     2, ..., 13520, 13521, 13522]),\n 'correct_answer': array([0, 1, 2, 3]),\n 'part': array([1, 2, 3, 4, 5, 6, 7])}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1638215855064
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split tags\n",
        "Tag `n` is renumbered to `n+1` so that 0 means \"no tag\""
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "questions_df[[f'tag_{_}' for _ in range(6)]] = (questions_df.tags.str.split(expand=True).fillna('-1').astype('int16') + 1).astype('uint8')"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1638215855897
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions_df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 13523 entries, 0 to 13522\nData columns (total 11 columns):\n #   Column          Non-Null Count  Dtype   \n---  ------          --------------  -----   \n 0   question_id     13523 non-null  category\n 1   bundle_id       13523 non-null  category\n 2   correct_answer  13523 non-null  category\n 3   part            13523 non-null  category\n 4   tags            13522 non-null  object  \n 5   tag_0           13523 non-null  uint8   \n 6   tag_1           13523 non-null  uint8   \n 7   tag_2           13523 non-null  uint8   \n 8   tag_3           13523 non-null  uint8   \n 9   tag_4           13523 non-null  uint8   \n 10  tag_5           13523 non-null  uint8   \ndtypes: category(4), object(1), uint8(6)\nmemory usage: 1.2+ MB\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1638215856688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions_df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "      question_id bundle_id correct_answer part            tags  tag_0  tag_1  \\\n0               0         0              0    1   51 131 162 38     52    132   \n1               1         1              1    1       131 36 81    132     37   \n2               2         2              0    1  131 101 162 92    132    102   \n3               3         3              0    1  131 149 162 29    132    150   \n4               4         4              3    1    131 5 162 38    132      6   \n...           ...       ...            ...  ...             ...    ...    ...   \n13518       13518     13518              3    5              14     15      0   \n13519       13519     13519              3    5               8      9      0   \n13520       13520     13520              2    5              73     74      0   \n13521       13521     13521              0    5             125    126      0   \n13522       13522     13522              3    5              55     56      0   \n\n       tag_2  tag_3  tag_4  tag_5  \n0        163     39      0      0  \n1         82      0      0      0  \n2        163     93      0      0  \n3        163     30      0      0  \n4        163     39      0      0  \n...      ...    ...    ...    ...  \n13518      0      0      0      0  \n13519      0      0      0      0  \n13520      0      0      0      0  \n13521      0      0      0      0  \n13522      0      0      0      0  \n\n[13523 rows x 11 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question_id</th>\n      <th>bundle_id</th>\n      <th>correct_answer</th>\n      <th>part</th>\n      <th>tags</th>\n      <th>tag_0</th>\n      <th>tag_1</th>\n      <th>tag_2</th>\n      <th>tag_3</th>\n      <th>tag_4</th>\n      <th>tag_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>51 131 162 38</td>\n      <td>52</td>\n      <td>132</td>\n      <td>163</td>\n      <td>39</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>131 36 81</td>\n      <td>132</td>\n      <td>37</td>\n      <td>82</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>131 101 162 92</td>\n      <td>132</td>\n      <td>102</td>\n      <td>163</td>\n      <td>93</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>131 149 162 29</td>\n      <td>132</td>\n      <td>150</td>\n      <td>163</td>\n      <td>30</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>131 5 162 38</td>\n      <td>132</td>\n      <td>6</td>\n      <td>163</td>\n      <td>39</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13518</th>\n      <td>13518</td>\n      <td>13518</td>\n      <td>3</td>\n      <td>5</td>\n      <td>14</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13519</th>\n      <td>13519</td>\n      <td>13519</td>\n      <td>3</td>\n      <td>5</td>\n      <td>8</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13520</th>\n      <td>13520</td>\n      <td>13520</td>\n      <td>2</td>\n      <td>5</td>\n      <td>73</td>\n      <td>74</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13521</th>\n      <td>13521</td>\n      <td>13521</td>\n      <td>0</td>\n      <td>5</td>\n      <td>125</td>\n      <td>126</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13522</th>\n      <td>13522</td>\n      <td>13522</td>\n      <td>3</td>\n      <td>5</td>\n      <td>55</td>\n      <td>56</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13523 rows × 11 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1638215857776
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions_df = questions_df.drop('tags', axis=1)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1638215858667
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert np.all(questions_df.isna() == False) # no nans\n",
        "assert np.all(questions_df.values < 2**16) # all fit in int16"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1638215859541
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qcols = questions_df.columns.to_list()\n",
        "QCols = enum.IntEnum('QCols', qcols, start=0)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1638215860372
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qcodes_d = {}\n",
        "for col, cats in qcats.items():\n",
        "    # code=0 is reserved for <NA>, NaN and the likes\n",
        "    qcodes_d[col] = { value: code+1 for code, value in enumerate(cats) }"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1638215861213
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qc_d = {}\n",
        "for row in questions_df.to_numpy():\n",
        "    question_id_code = qcodes_d['question_id'][row[QCols.question_id]]\n",
        "    qc_d[question_id_code] = np.array([\n",
        "        question_id_code,\n",
        "        qcodes_d['bundle_id'][row[QCols.bundle_id]],\n",
        "        qcodes_d['correct_answer'][row[QCols.correct_answer]],\n",
        "        qcodes_d['part'][row[QCols.part]],\n",
        "        row[QCols.tag_0],\n",
        "        row[QCols.tag_1],\n",
        "        row[QCols.tag_2],\n",
        "        row[QCols.tag_3],\n",
        "        row[QCols.tag_4],\n",
        "        row[QCols.tag_5],\n",
        "    ], dtype=np.int16)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1638215862232
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lectures"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "lecture_dtypes = {\n",
        "    'lecture_id': 'int64',\n",
        "    'tag': 'uint8',\n",
        "    'part': 'int8',\n",
        "    'type_of': 'object'\n",
        "}\n",
        "\n",
        "lectures_df = pd.read_csv(\n",
        "    in_d / 'lectures.csv',\n",
        "    usecols=lecture_dtypes.keys(),\n",
        "    dtype=lecture_dtypes,\n",
        ")\n",
        "\n",
        "lcats = categorize(lectures_df, ['lecture_id', 'part', 'type_of'])\n",
        "#lectures_cats"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1638215862956
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert np.all(lcats['part'] == qcats['part']) # all parts show up on both dfs"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1638215863788
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tags\n",
        "Tag `n` is renumbered to `n+1` here as well"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "lectures_df['tag_0'] = (lectures_df.tag.fillna('-1').astype('int16') + 1).astype('uint8')\n",
        "for i in range(1, 6):\n",
        "    lectures_df[f'tag_{i}']= pd.Series(0, index=lectures_df.index, dtype='uint8')"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1638215864717
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lectures_df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 10 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   lecture_id  418 non-null    category\n 1   tag         418 non-null    uint8   \n 2   part        418 non-null    category\n 3   type_of     418 non-null    category\n 4   tag_0       418 non-null    uint8   \n 5   tag_1       418 non-null    uint8   \n 6   tag_2       418 non-null    uint8   \n 7   tag_3       418 non-null    uint8   \n 8   tag_4       418 non-null    uint8   \n 9   tag_5       418 non-null    uint8   \ndtypes: category(3), uint8(7)\nmemory usage: 24.6 KB\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1638215865825
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lectures_df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "    lecture_id  tag part           type_of  tag_0  tag_1  tag_2  tag_3  tag_4  \\\n0           89  159    5           concept    160      0      0      0      0   \n1          100   70    1           concept     71      0      0      0      0   \n2          185   45    6           concept     46      0      0      0      0   \n3          192   79    5  solving question     80      0      0      0      0   \n4          317  156    5  solving question    157      0      0      0      0   \n..         ...  ...  ...               ...    ...    ...    ...    ...    ...   \n413      32535    8    5  solving question      9      0      0      0      0   \n414      32570  113    3  solving question    114      0      0      0      0   \n415      32604   24    6           concept     25      0      0      0      0   \n416      32625  142    2           concept    143      0      0      0      0   \n417      32736   82    3           concept     83      0      0      0      0   \n\n     tag_5  \n0        0  \n1        0  \n2        0  \n3        0  \n4        0  \n..     ...  \n413      0  \n414      0  \n415      0  \n416      0  \n417      0  \n\n[418 rows x 10 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lecture_id</th>\n      <th>tag</th>\n      <th>part</th>\n      <th>type_of</th>\n      <th>tag_0</th>\n      <th>tag_1</th>\n      <th>tag_2</th>\n      <th>tag_3</th>\n      <th>tag_4</th>\n      <th>tag_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>89</td>\n      <td>159</td>\n      <td>5</td>\n      <td>concept</td>\n      <td>160</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>70</td>\n      <td>1</td>\n      <td>concept</td>\n      <td>71</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>185</td>\n      <td>45</td>\n      <td>6</td>\n      <td>concept</td>\n      <td>46</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>192</td>\n      <td>79</td>\n      <td>5</td>\n      <td>solving question</td>\n      <td>80</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>317</td>\n      <td>156</td>\n      <td>5</td>\n      <td>solving question</td>\n      <td>157</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>32535</td>\n      <td>8</td>\n      <td>5</td>\n      <td>solving question</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>32570</td>\n      <td>113</td>\n      <td>3</td>\n      <td>solving question</td>\n      <td>114</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>32604</td>\n      <td>24</td>\n      <td>6</td>\n      <td>concept</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>32625</td>\n      <td>142</td>\n      <td>2</td>\n      <td>concept</td>\n      <td>143</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>32736</td>\n      <td>82</td>\n      <td>3</td>\n      <td>concept</td>\n      <td>83</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 10 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1638215866769
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lectures_df = lectures_df.drop('tag', axis=1)"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1638215867670
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert lectures_df.isna().sum().sum() == 0"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1638215868442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lcols = lectures_df.columns.to_list()\n",
        "LCols = enum.IntEnum('LCols', lcols, start=0)"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1638215869372
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lcodes_d = {}\n",
        "for col, cats in lcats.items():\n",
        "    # code=0 is reserved for <NA>, NaN and the likes\n",
        "    lcodes_d[col] = { value: code+1 for code, value in enumerate(cats) }"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1638215870114
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert max([ max(col_codes.values()) for col_codes in lcodes_d.values() ]) < 2**15 # fit in int16?"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1638215870858
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lc_d = {}\n",
        "for row in lectures_df.to_numpy():\n",
        "    lecture_id_code = lcodes_d['lecture_id'][row[LCols.lecture_id]]\n",
        "    lc_d[lecture_id_code] = np.array([\n",
        "        lecture_id_code,\n",
        "        lcodes_d['part'][row[LCols.part]],\n",
        "        lcodes_d['type_of'][row[LCols.type_of]],\n",
        "        row[LCols.tag_0],\n",
        "        row[LCols.tag_1],\n",
        "        row[LCols.tag_2],\n",
        "        row[LCols.tag_3],\n",
        "        row[LCols.tag_4],\n",
        "        row[LCols.tag_5],\n",
        "    ], dtype=np.int16)"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1638215871595
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interactions"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "interaction_dtypes = {\n",
        "    'row_id': 'int32',\n",
        "    'timestamp': 'int64',\n",
        "    'user_id': 'int32',\n",
        "    'content_id': 'int16',\n",
        "    'content_type_id': 'int8',\n",
        "    'task_container_id': 'int16',\n",
        "    'user_answer': 'int8',\n",
        "    'answered_correctly': 'int8',\n",
        "    'prior_question_elapsed_time': 'float32',\n",
        "    'prior_question_had_explanation': 'boolean'\n",
        "}\n",
        "\n",
        "i_df = pd.read_csv(\n",
        "    in_d / 'train.csv', \n",
        "    usecols=interaction_dtypes.keys(),\n",
        "    dtype=interaction_dtypes,\n",
        "    #nrows=10**6,\n",
        ")\n",
        "\n",
        "icats = categorize(i_df, ['task_container_id', 'user_answer', 'answered_correctly', 'prior_question_had_explanation'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 1min 42s, sys: 10.2 s, total: 1min 52s\nWall time: 2min 43s\n"
        }
      ],
      "execution_count": 29,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "i_df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 101230332 entries, 0 to 101230331\nData columns (total 10 columns):\n #   Column                          Dtype   \n---  ------                          -----   \n 0   row_id                          int32   \n 1   timestamp                       int64   \n 2   user_id                         int32   \n 3   content_id                      int16   \n 4   content_type_id                 int8    \n 5   task_container_id               category\n 6   user_answer                     category\n 7   answered_correctly              category\n 8   prior_question_elapsed_time     float32 \n 9   prior_question_had_explanation  category\ndtypes: category(4), float32(1), int16(1), int32(2), int64(1), int8(1)\nmemory usage: 2.6 GB\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1638216035483
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "icats['prior_question_had_explanation']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "array([False, True], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1638216035791
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "icols = i_df.columns.to_list()\n",
        "ICols = enum.IntEnum('ICols', icols, start=0)"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1638216036249
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "icols"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "['row_id',\n 'timestamp',\n 'user_id',\n 'content_id',\n 'content_type_id',\n 'task_container_id',\n 'user_answer',\n 'answered_correctly',\n 'prior_question_elapsed_time',\n 'prior_question_had_explanation']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1638216036584
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "icodes_d = {}\n",
        "for col, cats in icats.items():\n",
        "    # code=0 is reserved for <NA>, NaN and the likes\n",
        "    icodes_d[col] = { value: code+1 for code, value in enumerate(cats) }"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1638216036865
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hack in <NA> in cats_d['prior_question_had_explanation']\n",
        "icodes_d['prior_question_had_explanation'][pd.NA] = 0\n",
        "icodes_d['prior_question_had_explanation'][np.nan] = 0"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1638216037170
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_icode = max([ max(col_codes.values()) for col_codes in icodes_d.values() ])\n",
        "assert max_icode < 2**15 # fit in int16?"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1638216037469
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge all codes into codes_d"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "codes_d = { **icodes_d, **qcodes_d, **lcodes_d }"
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1638216037752
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_names = sorted([\n",
        "    'already_answered',          # has this question been answered before?\n",
        "    'answered_correctly',        # answered correctly by user\n",
        "    'bundle_id', \n",
        "    'correct_answer', \n",
        "    'lecture_id', \n",
        "    'part', \n",
        "    'qhe',                       # question has explanation (pqhe shifted upwards 1 container)\n",
        "    'question_id', \n",
        "    'task_container_id',\n",
        "    'type_of',                   # lecture type\n",
        "    'user_answer', \n",
        "])\n",
        "\n",
        "# To hide from decoder:\n",
        "# - answered_correctly\n",
        "# - user_answer\n",
        "# - qhe\n",
        "\n",
        "cont_names = sorted([\n",
        "    'attempt_num',               # number of attempts per user_id, question_id\n",
        "    'attempt_num_log',           # log1p of the above\n",
        "    'attempts_correct',          # number of CORRECT attempts per user_id, question_id\n",
        "    'attempts_correct_log',\n",
        "    'attempts_correct_avg',      # attempts_correct / attempts_num\n",
        "    'attempts_correct_avg_log',\n",
        "    'container_ord',             # ordinal of question within container\n",
        "    'qet',                       # question elapsed time (pqet shifted upwards 1 container)\n",
        "    'qet_log',\n",
        "    'qp',                        # probabilty of occurrence of this question\n",
        "    'qp_log',\n",
        "    'timestamp',                 # interaction ts\n",
        "    'timestamp_log',\n",
        "    'tsli',                      # time since last interaction (aka timestamp delta)\n",
        "    'tsli_log',\n",
        "    'clipped_tsli',              # tsli clipped to 20 minutes\n",
        "    'clipped_tsli_log',\n",
        "    'ts_mod_1day',               # timestamp modulus 1 day\n",
        "    'ts_mod_1day_sin',\n",
        "    'ts_mod_1day_cos',\n",
        "    'ts_mod_1week',              # timestamp modulus 1 week\n",
        "    'ts_mod_1week_sin',\n",
        "    'ts_mod_1week_cos',\n",
        "])\n",
        "\n",
        "# To hide from decoder:\n",
        "# - qet\n",
        "# - qet_log\n"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1638216038037
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Cats = enum.IntEnum('Cats', cat_names, start=0)\n",
        "Conts = enum.IntEnum('Conts', cont_names, start=0)"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1638216038461
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode user_ids\n",
        "This helps coo -> lil_matrix conversion to not freak out"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "users_d = defaultdict(lambda: len(users_d))\n",
        "for user_id in np.sort(i_df.user_id.unique()):\n",
        "    users_d[user_id]"
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1638216038823
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(users_d.keys()) == 393656\n",
        "assert np.all(np.array(list(users_d.keys())) == np.array(sorted(users_d.keys())))\n",
        "assert users_d[2746] == 2"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1638216039134
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find probabilty of occurrence of each question"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tmp_q_df = i_df[i_df.content_type_id == 0]\n",
        "qp_d = (tmp_q_df.content_id.value_counts() / len(tmp_q_df)).to_dict()\n",
        "del tmp_q_df"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 4.32 s, sys: 1.39 s, total: 5.7 s\nWall time: 5.73 s\n"
        }
      ],
      "execution_count": 42,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `update_questions`, `update_answers`, `get_x` "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def update_questions(df, Col, cat_names, cont_names, qc_d, lc_d, codes_d, QCols, LCols, Cats, Conts, \n",
        "        hist_cat_d, hist_cont_d, hist_tags_d, hist_tagw_d, last_q_container_d, last_ts, attempt_num, \n",
        "        attempts_correct, qp_d, users_d):\n",
        "    \n",
        "    df_a = df.values\n",
        "    \n",
        "    n_rows = len(df)\n",
        "    \n",
        "    # Prefetch tslis per (user_id, tcid) for better_tsli calculation\n",
        "    # NOTE the keys (user_id, tcid) are NOT encoded\n",
        "    tsli_d = defaultdict(list)\n",
        "    #for i, (_, row) in enumerate(df_d.items()): # SLOW\n",
        "    #for i, (_, row) in enumerate(df.iterrows()): # SUPER SLOW\n",
        "    for i, row in enumerate(df_a):\n",
        "        user_id, tcid, ts = row[Col.user_id], row[Col.task_container_id], row[Col.timestamp]\n",
        "        encoded_user_id = users_d[user_id]\n",
        "        tsli_d[user_id, tcid].append(ts - last_ts[encoded_user_id,0])\n",
        "        last_ts[encoded_user_id,0] = np.int64(ts)\n",
        "        \n",
        "    # average all tslis in the same task container\n",
        "    tsli_d = { k: sum(v)/len(v) for k, v in tsli_d.items() }\n",
        "    \n",
        "    # append df data to history\n",
        "    for i, row in enumerate(df_a):\n",
        "        user_id = row[Col.user_id]\n",
        "        encoded_user_id = users_d[user_id]\n",
        "        user_has_hist = user_id in hist_cat_d\n",
        "        if user_has_hist:\n",
        "            h_cat  = hist_cat_d [user_id] # just shortcuts\n",
        "            h_cont = hist_cont_d[user_id]\n",
        "            h_tags = hist_tags_d[user_id]\n",
        "            h_tagw = hist_tagw_d[user_id]\n",
        "        \n",
        "        cat  = np.zeros(len(cat_names),  dtype=np.int16)\n",
        "        cont = np.full (len(cont_names), np.nan, dtype=np.float32)\n",
        "\n",
        "        # Categorical test data\n",
        "        content_id = row[Col.content_id]\n",
        "        is_question = row[Col.content_type_id] == 0\n",
        "\n",
        "        if is_question:\n",
        "            encoded_question_id = codes_d['question_id'][content_id]\n",
        "            qc_row = qc_d[encoded_question_id]\n",
        "            cat[Cats.bundle_id]        = qc_row[QCols.bundle_id]\n",
        "            cat[Cats.correct_answer]   = qc_row[QCols.correct_answer]\n",
        "            cat[Cats.part]             = qc_row[QCols.part]\n",
        "            cat[Cats.question_id]      = encoded_question_id\n",
        "            cat[Cats.already_answered] = (int)(attempt_num[encoded_user_id, encoded_question_id-1] > 0)\n",
        "            cat[Cats.qhe]              = 0  # question has explanation?, not known yet    \n",
        "        else:\n",
        "            encoded_lecture_id = codes_d['lecture_id'][content_id]\n",
        "            lc_row = lc_d[encoded_lecture_id]\n",
        "            cat[Cats.lecture_id] = encoded_lecture_id\n",
        "            cat[Cats.part]       = lc_row[LCols.part]\n",
        "            cat[Cats.type_of]    = lc_row[LCols.type_of]\n",
        "\n",
        "        tcid = row[Col.task_container_id]\n",
        "        encoded_pqhe = codes_d['prior_question_had_explanation'][row[Col.prior_question_had_explanation]]\n",
        "        encoded_tcid = codes_d['task_container_id'][tcid]\n",
        "        cat[Cats.task_container_id] = encoded_tcid\n",
        "        \n",
        "        # Continuous test data\n",
        "        ts = row[Col.timestamp]\n",
        "        ts_mod_1day = ts % (1000 * 60 * 60 * 24)\n",
        "        ts_mod_1week = ts % (1000 * 60 * 60 * 24 * 7)\n",
        "        pqet = row[Col.prior_question_elapsed_time]\n",
        "        tsli = tsli_d[(user_id, tcid)] if user_has_hist else np.nan\n",
        "        clipped_tsli = min(tsli, 1000 * 60 * 20) # 20 minutes\n",
        "        \n",
        "        cont[Conts.qet]              = np.nan\n",
        "        cont[Conts.timestamp]        = ts\n",
        "        cont[Conts.tsli]             = tsli\n",
        "        cont[Conts.clipped_tsli]     = clipped_tsli\n",
        "        cont[Conts.qet_log]          = np.nan\n",
        "        cont[Conts.timestamp_log]    = np.log1p(ts)\n",
        "        cont[Conts.tsli_log]         = np.log1p(tsli)\n",
        "        cont[Conts.clipped_tsli_log] = np.log1p(clipped_tsli)\n",
        "        cont[Conts.ts_mod_1day]      = ts_mod_1day\n",
        "        cont[Conts.ts_mod_1day_sin]  = np.sin(ts_mod_1day * 2 * np.pi / (1000 * 60 * 60 * 24))\n",
        "        cont[Conts.ts_mod_1day_cos]  = np.cos(ts_mod_1day * 2 * np.pi / (1000 * 60 * 60 * 24))\n",
        "        cont[Conts.ts_mod_1week]     = ts_mod_1week\n",
        "        cont[Conts.ts_mod_1week_sin] = np.sin(ts_mod_1week * 2 * np.pi / (1000 * 60 * 60 * 24 * 7))\n",
        "        cont[Conts.ts_mod_1week_cos] = np.cos(ts_mod_1week * 2 * np.pi / (1000 * 60 * 60 * 24 * 7))\n",
        "        \n",
        "        # container ordinal\n",
        "        if user_has_hist and h_cat[-1,Cats.task_container_id] == encoded_tcid:\n",
        "            cont[Conts.container_ord] = h_cont[-1,Conts.container_ord] + 1\n",
        "        else:\n",
        "            cont[Conts.container_ord] = 0\n",
        "        \n",
        "        if is_question:\n",
        "            # Update qet and qet_log in history (make qet in last bundle skipping lectures = pqet)\n",
        "            if user_id in last_q_container_d and encoded_tcid != last_q_container_d[user_id]:\n",
        "                idx = h_cat[:,Cats.task_container_id] == last_q_container_d[user_id]\n",
        "                h_cat [idx,Cats.qhe]      = encoded_pqhe\n",
        "                h_cont[idx,Conts.qet]     = pqet\n",
        "                h_cont[idx,Conts.qet_log] = np.log1p(pqet)\n",
        "                        \n",
        "            last_q_container_d[user_id] = encoded_tcid\n",
        "            \n",
        "            # Update attempt_num\n",
        "            an = attempt_num     [encoded_user_id, encoded_question_id-1] # np.uint8\n",
        "            ac = attempts_correct[encoded_user_id, encoded_question_id-1] # np.uint8\n",
        "            cont[Conts.attempt_num]              = an\n",
        "            cont[Conts.attempt_num_log]          = np.log1p(an)\n",
        "            \n",
        "            # Update attempts_correct with what we know so far (will be re-updated after we've got the answers)\n",
        "            cont[Conts.attempts_correct]         = ac\n",
        "            cont[Conts.attempts_correct_log]     = np.log1p(ac)\n",
        "            if an != 0:\n",
        "                cont[Conts.attempts_correct_avg]     = ac / an\n",
        "                cont[Conts.attempts_correct_avg_log] = np.log1p(ac / an)\n",
        "\n",
        "            attempt_num[encoded_user_id, encoded_question_id-1] += np.uint8(1)\n",
        "\n",
        "            # question occurrence prob\n",
        "            cont[Conts.qp]              = qp_d[content_id] # qp_d indexes are non-encoded qids\n",
        "            cont[Conts.qp_log]          = np.log1p(cont[Conts.qp])\n",
        "\n",
        "        # Tags and weights\n",
        "        if is_question:\n",
        "            tags = qc_row[[ QCols.tag_0, QCols.tag_1, QCols.tag_2, QCols.tag_3, QCols.tag_4, QCols.tag_5 ]]\n",
        "        else:\n",
        "            tags = lc_row[[ LCols.tag_0, LCols.tag_1, LCols.tag_2, LCols.tag_3, LCols.tag_4, LCols.tag_5 ]]\n",
        "        tags = tags.astype(np.uint8)\n",
        "        tagw = (tags != 0).astype(np.float16)\n",
        "        sums = tagw.sum()\n",
        "        if sums > 0:\n",
        "            tagw /= sums\n",
        "       \n",
        "        # Concat history and new test data\n",
        "        if user_has_hist:\n",
        "            hist_cat_d [user_id] = np.concatenate((h_cat,  np.expand_dims(cat,  0)))\n",
        "            hist_cont_d[user_id] = np.concatenate((h_cont, np.expand_dims(cont, 0)))\n",
        "            hist_tags_d[user_id] = np.concatenate((h_tags, np.expand_dims(tags, 0)))\n",
        "            hist_tagw_d[user_id] = np.concatenate((h_tagw, np.expand_dims(tagw, 0)))\n",
        "        else:\n",
        "            hist_cat_d [user_id] = np.expand_dims(cat,  0)\n",
        "            hist_cont_d[user_id] = np.expand_dims(cont, 0)\n",
        "            hist_tags_d[user_id] = np.expand_dims(tags, 0)\n",
        "            hist_tagw_d[user_id] = np.expand_dims(tagw, 0)\n",
        "\n",
        "    return df.user_id.values\n",
        "\n",
        "\n",
        "def update_answers(prior_user_ids, prior_group_answers_correct, prior_group_responses, \n",
        "        cat_names, cont_names, codes_d, hist_cat_d, hist_cont_d, users_d, attempt_num, attempts_correct):\n",
        "\n",
        "    idx_per_uid_d = defaultdict(int)\n",
        "    for uid in prior_user_ids:\n",
        "        idx_per_uid_d[uid] -= 1\n",
        "\n",
        "    for i, uid in enumerate(prior_user_ids):\n",
        "        h_cat  = hist_cat_d [uid] # just shortcuts\n",
        "        h_cont = hist_cont_d[uid]\n",
        "        \n",
        "        idx = idx_per_uid_d[uid]\n",
        "        idx_per_uid_d[uid] += 1\n",
        "        \n",
        "        # Update categorical vars\n",
        "        h_cat [idx,Cats.answered_correctly] = codes_d['answered_correctly'][prior_group_answers_correct[i]]\n",
        "        h_cat [idx,Cats.user_answer]        = codes_d['user_answer'][prior_group_responses[i]]\n",
        "\n",
        "        # Update continuous vars\n",
        "        eqid = h_cat[idx,Cats.question_id]\n",
        "        if eqid > 0: # it's a question\n",
        "            assert prior_group_answers_correct[i] >= 0\n",
        "            euid = users_d[uid]\n",
        "            ac = attempts_correct[euid,eqid-1] # np.int8\n",
        "            an = h_cont[idx,Conts.attempt_num] # np.float32\n",
        "            h_cont[idx,Conts.attempts_correct]         = ac\n",
        "            h_cont[idx,Conts.attempts_correct_log]     = np.log1p(ac)\n",
        "            if an != 0:\n",
        "                h_cont[idx,Conts.attempts_correct_avg]     = ac / an\n",
        "                h_cont[idx,Conts.attempts_correct_avg_log] = np.log1p(ac / an)\n",
        "\n",
        "            attempts_correct[euid,eqid-1] = ac + np.uint8(prior_group_answers_correct[i])\n",
        "        else:\n",
        "            assert prior_group_answers_correct[i] == -1"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1638216041964
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ```proxy_append_df```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def proxy_append_df(df):\n",
        "    hist_cat_d         = {}\n",
        "    hist_cont_d        = {}\n",
        "    hist_tags_d        = {}\n",
        "    hist_tagw_d        = {}\n",
        "    last_q_container_d = {}\n",
        "    last_ts            = defaultdict(np.int64)\n",
        "    attempt_num        = defaultdict(np.uint8)\n",
        "    attempts_correct   = defaultdict(np.uint8)\n",
        "    chunk_size         = None\n",
        "    Col                = enum.IntEnum('Col', df.columns.tolist(), start=0)\n",
        "\n",
        "    # update questions\n",
        "    prior_user_ids = update_questions(\n",
        "        df, Col, cat_names, cont_names, qc_d, lc_d, codes_d, QCols, LCols, Cats, Conts, \n",
        "        hist_cat_d, hist_cont_d, hist_tags_d, hist_tagw_d, last_q_container_d, last_ts, \n",
        "        attempt_num, attempts_correct, qp_d, users_d)\n",
        "\n",
        "    # update answers\n",
        "    prior_group_answers_correct = df.answered_correctly.values\n",
        "    prior_group_responses       = df.user_answer.values\n",
        "\n",
        "    update_answers(prior_user_ids, prior_group_answers_correct, prior_group_responses, \n",
        "        cat_names, cont_names, codes_d, hist_cat_d, hist_cont_d, users_d, attempt_num, attempts_correct)\n",
        "    \n",
        "    return (hist_cat_d, hist_cont_d, hist_tags_d, hist_tagw_d, \n",
        "            last_q_container_d, last_ts, attempt_num, attempts_correct)"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1638216042313
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test `append_df`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#%lprun -f update_answers (\n",
        "#    hist_cat_d, hist_cont_d, hist_tags_d, hist_tagw_d, \n",
        "#    last_last_q_container_d, last_ts, attempt_num, previous_ac) = proxy_append_df(i_df[:100000])"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1638216042594
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "#(hist_cat_d, hist_cont_d, hist_tags_d, hist_tagw_d,\n",
        "# last_last_q_container_d, last_ts, attempt_num, attempts_correct) = proxy_append_df(i_df[:100000])"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1638216042999
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* pytorch.sparse -> 32s and can't parallelize (\"torch sparse tensor has no storage\" error)\n",
        "* scipy.sparse.dok_matrix -> 17.5s\n",
        "* scipy.sparse.lil_matrix -> 15.4s\n",
        "* scipy.sparse.csr_matrix -> minutes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.set_option('display.max_rows', 1000)\n",
        "#pd.set_option('display.max_columns', None)"
      ],
      "outputs": [],
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1638216043305
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interesting user_ids:\n",
        "\n",
        "- 8623 (3 containers x 5 questions)\n",
        "- 124 (1 container, meaningful tsli)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#i_df[i_df.user_id == 8623]"
      ],
      "outputs": [],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1638216043580
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.DataFrame(hist_ord_d[8623], columns=['ordinal'])"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1638216043854
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.DataFrame(hist_cat_d[8623], columns=cat_names)"
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1638216044140
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just for the header\n",
        "#pd.DataFrame(hist_cont_d[8623][:1], columns=cont_names)"
      ],
      "outputs": [],
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1638216044426
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test_df = pd.DataFrame(hist_cont_d[8623], columns=cont_names)"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1638216044736
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test_df"
      ],
      "outputs": [],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1638216045039
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test_df[test_df.attempt_num > 1]"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1638216045410
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#all_cont = np.concatenate(list(v for v in hist_cont_d.values()))"
      ],
      "outputs": [],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1638216045694
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#_=plt.hist(np.log1p(all_cont[:,Conts.tsli]), bins=100)"
      ],
      "outputs": [],
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1638216046004
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#np.exp(14) / 1000 / 60"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1638216046282
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.DataFrame(hist_cat_d[124], columns=cat_names)"
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {
        "gather": {
          "logged": 1638216046555
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.DataFrame(hist_cont_d[115], columns=cont_names)"
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1638216046861
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create training data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "bins = np.linspace(i_df.user_id.min()-1, i_df.user_id.max(), num=1024+1, dtype=np.int32)"
      ],
      "outputs": [],
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1638216047130
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfg = i_df.groupby(pd.cut(i_df.user_id, bins))"
      ],
      "outputs": [],
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1638216047543
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "groups = [ dfg.get_group(_) for _ in dfg.groups.keys() ]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 5.8 s, sys: 2.51 s, total: 8.31 s\nWall time: 8.31 s\n"
        }
      ],
      "execution_count": 62,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with ProcessPoolExecutor() as e:\n",
        "    res = list(tqdm(e.map(proxy_append_df, groups), total=len(groups)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 1024/1024 [16:28<00:00,  1.04it/s]\n"
        }
      ],
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1638217043556
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "merge_dicts = lambda idx: { k: v for d in [ _[idx] for _ in res ] for k, v in d.items() }\n",
        "cat_d                 = merge_dicts(0)\n",
        "cont_d                = merge_dicts(1)\n",
        "tags_d                = merge_dicts(2)\n",
        "tagw_d                = merge_dicts(3)\n",
        "last_q_container_id_d = merge_dicts(4)\n",
        "last_ts               = merge_dicts(5)\n",
        "attempt_num           = merge_dicts(6)\n",
        "attempts_correct      = merge_dicts(7)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 1min 4s, sys: 10.7 s, total: 1min 15s\nWall time: 1min 15s\n"
        }
      ],
      "execution_count": 64,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dok matrices"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "assert all(v.dtype == np.int64 for v in last_ts.values())\n",
        "assert all(v.dtype == np.uint8 for v in attempt_num.values())\n",
        "assert all(v.dtype == np.uint8 for v in attempts_correct.values())"
      ],
      "outputs": [],
      "execution_count": 65,
      "metadata": {
        "gather": {
          "logged": 1638217154202
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_ts_dok          = dok_matrix((H.max_users, 1), dtype=np.int64)\n",
        "attempt_num_dok      = dok_matrix((H.max_users, H.max_questions), dtype=np.uint8)\n",
        "attempts_correct_dok = dok_matrix((H.max_users, H.max_questions), dtype=np.uint8)"
      ],
      "outputs": [],
      "execution_count": 66,
      "metadata": {
        "gather": {
          "logged": 1638217154534
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_ts_dok._update(last_ts)"
      ],
      "outputs": [],
      "execution_count": 67,
      "metadata": {
        "gather": {
          "logged": 1638217155090
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attempt_num_dok._update(attempt_num)"
      ],
      "outputs": [],
      "execution_count": 68,
      "metadata": {
        "gather": {
          "logged": 1638217170207
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attempts_correct_dok._update(attempts_correct)"
      ],
      "outputs": [],
      "execution_count": 69,
      "metadata": {
        "gather": {
          "logged": 1638217183918
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#del res  # this barely has an effect\n",
        "#gc.collect()"
      ],
      "outputs": [],
      "execution_count": 70,
      "metadata": {
        "gather": {
          "logged": 1638217184246
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert dok -> array or coo\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "last_ts_dok"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 71,
          "data": {
            "text/plain": "<450000x1 sparse matrix of type '<class 'numpy.int64'>'\n\twith 393656 stored elements in Dictionary Of Keys format>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1638217184625
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "last_ts = last_ts_dok.toarray()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 72.3 ms, sys: 16.1 ms, total: 88.4 ms\nWall time: 87.8 ms\n"
        }
      ],
      "execution_count": 72,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "attempt_num_dok"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 73,
          "data": {
            "text/plain": "<450000x13523 sparse matrix of type '<class 'numpy.uint8'>'\n\twith 86867031 stored elements in Dictionary Of Keys format>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1638217185480
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "attempt_num_coo = attempt_num_dok.tocoo()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 19.6 s, sys: 1.06 s, total: 20.7 s\nWall time: 20.7 s\n"
        }
      ],
      "execution_count": 74,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "attempts_correct_dok"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 75,
          "data": {
            "text/plain": "<450000x13523 sparse matrix of type '<class 'numpy.uint8'>'\n\twith 86867031 stored elements in Dictionary Of Keys format>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1638217205117
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "attempts_correct_coo = attempts_correct_dok.tocoo()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 14 s, sys: 194 ms, total: 14.2 s\nWall time: 14.2 s\n"
        }
      ],
      "execution_count": 76,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "del attempt_num, attempts_correct\n",
        "gc.collect()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 77,
          "data": {
            "text/plain": "20"
          },
          "metadata": {}
        }
      ],
      "execution_count": 77,
      "metadata": {
        "gather": {
          "logged": 1638217256918
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(last_q_container_id_d) == len(cat_d) == len(i_df.user_id.unique()) "
      ],
      "outputs": [],
      "execution_count": 78,
      "metadata": {
        "gather": {
          "logged": 1638217257367
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert attempt_num_coo.getnnz() == 86867031"
      ],
      "outputs": [],
      "execution_count": 79,
      "metadata": {
        "gather": {
          "logged": 1638217257669
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ts = i_df.groupby('user_id')['timestamp'].max().values\n",
        "np.testing.assert_equal(test_ts, last_ts[:len(test_ts),0])"
      ],
      "outputs": [],
      "execution_count": 80,
      "metadata": {
        "gather": {
          "logged": 1638217259456
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding sizes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "n_emb = {\n",
        "    'already_answered': 2,\n",
        "    'answered_correctly': 4,\n",
        "    'bundle_id': 9766,\n",
        "    'correct_answer': 5,\n",
        "    'lecture_id': 419,\n",
        "    'part': 8,\n",
        "    'prior_question_had_explanation': 3,\n",
        "    'question_id': 13524,\n",
        "    'task_container_id': 10001,\n",
        "    'type_of': 5,\n",
        "    'user_answer': 6\n",
        "}\n",
        "\n",
        "emb_dim = {\n",
        "    'already_answered': 1,\n",
        "    'answered_correctly': 3,\n",
        "    'bundle_id': 274,\n",
        "    'correct_answer': 4,\n",
        "    'lecture_id': 47,\n",
        "    'part': 5,\n",
        "    'prior_question_had_explanation': 3,\n",
        "    'question_id': 329,\n",
        "    'task_container_id': 278,\n",
        "    'type_of': 4,\n",
        "    'user_answer': 4\n",
        "}\n",
        "\n",
        "tags_n_emb = 187+2 # [0..max_tag, max_tag+1]. max_tag+1 = empty tag \n",
        "tags_emb_dim = tags_n_emb # emb_sz_rule(tags_n_emb)"
      ],
      "outputs": [],
      "execution_count": 81,
      "metadata": {
        "gather": {
          "logged": 1638217259762
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some checks"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "all_cat = np.concatenate(list(cat_d.values()))\n",
        "assert np.isnan(all_cat).sum() == 0"
      ],
      "outputs": [],
      "execution_count": 82,
      "metadata": {
        "gather": {
          "logged": 1638217262710
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert tags_d[115].dtype == np.uint8"
      ],
      "outputs": [],
      "execution_count": 83,
      "metadata": {
        "gather": {
          "logged": 1638217263152
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Means and stds of continuous vars"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "all_cont = np.concatenate(list(cont_d.values()))\n",
        "assert all_cont.shape[0] == len(i_df)"
      ],
      "outputs": [],
      "execution_count": 84,
      "metadata": {
        "gather": {
          "logged": 1638217268442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert np.nanmax(all_cont[:,Conts.attempt_num]) == 82"
      ],
      "outputs": [],
      "execution_count": 85,
      "metadata": {
        "gather": {
          "logged": 1638217269082
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#assert np.isnan(all_cont[:,Conts.prior_question_elapsed_time]).sum() == i_df.prior_question_elapsed_time.isna().sum()"
      ],
      "outputs": [],
      "execution_count": 86,
      "metadata": {
        "gather": {
          "logged": 1638217269410
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "means = np.nanmean(all_cont, axis=0, dtype=np.float64)\n",
        "stds  = np.nanstd (all_cont, axis=0, dtype=np.float64)"
      ],
      "outputs": [],
      "execution_count": 87,
      "metadata": {
        "gather": {
          "logged": 1638217313633
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxs = np.nanmax(all_cont, axis=0)\n",
        "mins = np.nanmin(all_cont, axis=0)"
      ],
      "outputs": [],
      "execution_count": 88,
      "metadata": {
        "gather": {
          "logged": 1638217335517
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cont_names, means, stds, maxs, mins"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 89,
          "data": {
            "text/plain": "(['attempt_num',\n  'attempt_num_log',\n  'attempts_correct',\n  'attempts_correct_avg',\n  'attempts_correct_avg_log',\n  'attempts_correct_log',\n  'clipped_tsli',\n  'clipped_tsli_log',\n  'container_ord',\n  'qet',\n  'qet_log',\n  'qp',\n  'qp_log',\n  'timestamp',\n  'timestamp_log',\n  'ts_mod_1day',\n  'ts_mod_1day_cos',\n  'ts_mod_1day_sin',\n  'ts_mod_1week',\n  'ts_mod_1week_cos',\n  'ts_mod_1week_sin',\n  'tsli',\n  'tsli_log'],\n array([1.71275676e-01, 1.02451578e-01, 6.78789338e-02, 3.60193529e-01,\n        2.56868295e-01, 4.17399861e-02, 1.62953342e+05, 1.10097465e+01,\n        4.04873294e-01, 2.59525175e+04, 9.92678915e+00, 2.54023347e-04,\n        2.53917140e-04, 7.70364365e+09, 2.08774076e+01, 3.85844342e+07,\n        2.39129433e-01, 1.60690095e-02, 2.58239902e+08, 1.16058160e-01,\n        5.14945556e-02, 2.00618321e+07, 1.12457744e+01]),\n array([5.84928336e-01, 2.86078097e-01, 3.70166409e-01, 4.47063082e-01,\n        3.12723449e-01, 1.84429290e-01, 3.23172954e+05, 1.19666667e+00,\n        8.40763914e-01, 2.04180510e+04, 8.28739183e-01, 3.84824433e-04,\n        3.84496934e-04, 1.15926553e+10, 3.33278846e+00, 2.89322120e+07,\n        7.21060451e-01, 6.50100564e-01, 1.87675544e+08, 7.32093081e-01,\n        6.69267159e-01, 4.68762026e+08, 1.94163643e+00]),\n array([8.2000000e+01, 4.4179688e+00, 8.2000000e+01, 1.0000000e+00,\n        6.9314718e-01, 4.4179688e+00, 1.2000000e+06, 1.3997833e+01,\n        9.0000000e+00, 3.0000000e+05, 1.2611541e+01, 2.1517295e-03,\n        2.1494180e-03, 8.7425769e+10, 2.5194056e+01, 8.6400000e+07,\n        1.0000000e+00, 1.0000000e+00, 6.0480000e+08, 1.0000000e+00,\n        1.0000000e+00, 8.3884261e+10, 2.5152704e+01], dtype=float32),\n array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0073405e-08,\n         1.0073405e-08,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n        -1.0000000e+00, -1.0000000e+00,  0.0000000e+00, -1.0000000e+00,\n        -1.0000000e+00,  0.0000000e+00,  0.0000000e+00], dtype=float32))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 89,
      "metadata": {
        "gather": {
          "logged": 1638217336532
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "means[Conts.tsli]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 90,
          "data": {
            "text/plain": "20061832.085879758"
          },
          "metadata": {}
        }
      ],
      "execution_count": 90,
      "metadata": {
        "gather": {
          "logged": 1638217337053
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert np.abs(means[Conts.timestamp] - 7703643654.326523) < 0.1 # vs 52\n",
        "#assert np.abs(means[Conts.prior_question_elapsed_time] - 25423.844) < 0.1 # vs 52\n",
        "assert np.abs(means[Conts.tsli] - 20061832.08) < 50 # vs 201221 (precise timestamp)\n",
        "assert np.abs(means[Conts.qet] - 2.59525175e+04) < 0.1 # vs 62, TODO: fix bundle_id -> tcid in 52 and get baseline"
      ],
      "outputs": [],
      "execution_count": 91,
      "metadata": {
        "gather": {
          "logged": 1638217337601
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.set_option('display.max_rows', 128)"
      ],
      "outputs": [],
      "execution_count": 92,
      "metadata": {
        "gather": {
          "logged": 1638217338275
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.DataFrame(all_cont[:100], columns=cont_names)"
      ],
      "outputs": [],
      "execution_count": 93,
      "metadata": {
        "gather": {
          "logged": 1638217338820
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.DataFrame(all_cat[:100], columns=cat_names)"
      ],
      "outputs": [],
      "execution_count": 94,
      "metadata": {
        "gather": {
          "logged": 1638217339534
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pickle train data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "WTF, can't pickle enums... We'll rebuild them at train/infer\n",
        "```\n",
        "QCols = enum.IntEnum('QCols', meta.qcols, start=0)\n",
        "LCols = enum.IntEnum('LCols', meta.lcols, start=0)\n",
        "Cats  = enum.IntEnum('Cats',  meta.cat_names, start=0)\n",
        "Conts = enum.IntEnum('Conts', meta.cont_names, start=0)\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "meta = _H(\n",
        "    means=means,\n",
        "    stds=stds,\n",
        "    maxs=maxs,\n",
        "    mins=mins,\n",
        "    qc_d=qc_d,\n",
        "    qcats=qcats,\n",
        "    qcols=qcols,\n",
        "    qcodes_d=qcodes_d,\n",
        "    lc_d=lc_d,\n",
        "    lcats=lcats,\n",
        "    lcols=lcols,\n",
        "    lcodes_d=lcodes_d,\n",
        "    codes_d=codes_d,\n",
        "    cat_names=cat_names,\n",
        "    cont_names=cont_names,\n",
        "    icats=icats,\n",
        "    n_emb=n_emb,\n",
        "    emb_dim=emb_dim,\n",
        "    tags_n_emb=tags_n_emb,\n",
        "    tags_emb_dim=tags_emb_dim,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 95,
      "metadata": {
        "gather": {
          "logged": 1638217340203
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = _H(\n",
        "    cat_d=cat_d,\n",
        "    cont_d=cont_d,\n",
        "    tags_d=tags_d,\n",
        "    tagw_d=tagw_d,\n",
        "    last_q_contained_id_d=last_q_container_id_d,\n",
        "    attempt_num_coo=attempt_num_coo,\n",
        "    attempts_correct_coo=attempts_correct_coo,\n",
        "    last_ts=last_ts,\n",
        "    qp_d=qp_d,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 96,
      "metadata": {
        "gather": {
          "logged": 1638217340781
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H.version"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 97,
          "data": {
            "text/plain": "'210101b'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 97,
      "metadata": {
        "gather": {
          "logged": 1638217341497
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with open(in_d / f'data_v{H.version}.pkl', 'wb') as f:\n",
        "    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 4min 27s, sys: 52.7 s, total: 5min 20s\nWall time: 5min 20s\n"
        }
      ],
      "execution_count": 98,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with open(in_d / f'meta_v{H.version}.pkl', 'wb') as f:\n",
        "    pickle.dump(meta, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 19.3 s, sys: 1.96 s, total: 21.3 s\nWall time: 21.3 s\n"
        }
      ],
      "execution_count": 99,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Execution time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "--- Execution time: 1830.0855379104614 seconds ---\n"
        }
      ],
      "execution_count": 100,
      "metadata": {
        "gather": {
          "logged": 1638217678351
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "azureml_py38_pytorch",
      "language": "python",
      "display_name": "Python 3.8 - PyTorch"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "toc": {
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "283px"
      },
      "skip_h1_title": false,
      "number_sections": true,
      "title_cell": "Table of Contents",
      "toc_window_display": true,
      "base_numbering": 1,
      "toc_section_display": true,
      "title_sidebar": "Contents",
      "toc_cell": false,
      "nav_menu": {
        "height": "292px",
        "width": "228px"
      },
      "sideBar": true
    },
    "kernel_info": {
      "name": "azureml_py38_pytorch"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}