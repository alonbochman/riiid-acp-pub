{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Added cell to measure execution time\r\n",
        "import time\r\n",
        "start_time = time.time()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638222162922
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run distributed:\n",
        "\n",
        "```\n",
        "make\n",
        "```\n",
        "\n",
        "```\n",
        "CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --master_port 1235 --nproc_per_node=4 02_train.py --epochs 10 --bs 48 --fp16 to_fp16 --trf_heads 4 --mixup False --chunk_size 500 --trf_dim 512 --loss ce --n_chunks 1 --fit fit_flat_cos --fit_kwargs pct_start=0.5 div_final=100 --tfixup True --pad r --valid_pct 0.025 --trf_act gelu --opt ranger_lamb --lr 3e-3\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import fastai"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1638222163630
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.basics       import *\n",
        "from fastai.callback.all import *\n",
        "from fastai.distributed  import *\n",
        "from fastai.tabular.all  import *\n",
        "from fastai.test_utils   import *\n",
        "\n",
        "import ast\n",
        "import enum\n",
        "import gc\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import enum\n",
        "\n",
        "from collections import defaultdict\n",
        "from fastcore.script import *\n",
        "from matplotlib import pyplot as plt\n",
        "from pathlib import Path\n",
        "from pytorch_block_sparse.util import ModelPatcher\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.distributions.beta import Beta\n",
        "from torch.utils.data import Dataset"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1638222188034
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_d = Path('../input')"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1638222188500
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@call_parse\n",
        "def main(\n",
        "    model:         Param(\"Name\", str) = '210105',\n",
        "    data:          Param(\"Data version\", str) = '210101b',\n",
        "    load:          Param(\"Load from\", str) = None,\n",
        "    validate:      Param(\"\", action='store_true') = False,\n",
        "    chunk_size:    Param(\"Chunk size\", int) = 500,\n",
        "    n_chunks:      Param(\"Number of chunks\", int) = 1,\n",
        "    #chunk_size:    Param(\"Chunk size\", int) = 50,  \n",
        "    #n_chunks:      Param(\"Number of chunks\", int) = 10,    \n",
        "    #bs:            Param(\"BS\", int) = 96,\n",
        "    bs:            Param(\"BS\", int) = 48,    #2 works, 96 doesn't\n",
        "    workers:       Param(\"\", int) = 8,\n",
        "    valid_pct:     Param(\"Validation set\", float) = 0.025,\n",
        "    trf_dim:       Param(\"\", int) = 512,\n",
        "    trf_enc:       Param(\"\", int) = 4,\n",
        "    trf_dec:       Param(\"\", int) = 4,\n",
        "    trf_heads:     Param(\"\", int) = 4,\n",
        "    trf_do:        Param(\"\", float) = 0.1,\n",
        "    trf_act:       Param(\"\", str) = 'gelu',\n",
        "    lr:            Param(\"\", float) = 3e-3,\n",
        "    clip:          Param(\"\", float) = 0.,\n",
        "    \n",
        "    moms:          Param(\"Moms for fit_one_cycle\", float, nargs='+') = (0.95,0.85,0.95),\n",
        "    epochs:        Param(\"Epochs\", int) = 10, #Original was 30,\n",
        "    tfixup:        Param(\"Use T-Fixup init\", ast.literal_eval) = True,\n",
        "    mixup:         Param(\"Use mixup\", ast.literal_eval) = False,\n",
        "    opt:           Param(\"Optimizer\", str) = 'ranger_lamb',\n",
        "    opt_kwargs:    Param(\"Optional args for opt, eg. eps=1e-4\", str, nargs='+') = {},\n",
        "    fit:           Param(\"fit or fit_one_cycle\", str) = 'fit_flat_cos',\n",
        "    fit_kwargs:    Param(\"Optional args for fit,eg pct_start=0.1\", str, nargs='+') = ['pct_start=0.5', 'div_final=100.'],\n",
        "    fp16:          Param(\"fp16 method: to_fp16, to_native_fp16, none\", str) = 'to_fp16',\n",
        "    \n",
        "    loss:          Param(\"Loss\", str) = 'ce',\n",
        "    \n",
        "    wua:           Param(\"Weight of user_answer term in the loss\", float) = 0.,\n",
        "    pad:           Param (\"Pad left of right (l|r)\",str,choices=['l','r'])='r',\n",
        "\n",
        "    local_rank:    Param(\"--local_rank\", int) = None,\n",
        "): \n",
        "    if opt_kwargs: opt_kwargs = {s.split('=')[0]:float(s.split('=')[1]) for s in opt_kwargs}\n",
        "    if fit_kwargs: fit_kwargs = {s.split('=')[0]:float(s.split('=')[1]) for s in fit_kwargs}\n",
        "    print(locals())\n",
        "    globals().update({ 'H' : AttrDict(locals())})\n",
        "_H = AttrDict"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1638222189118
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'model': '210105', 'data': '210101b', 'load': None, 'validate': False, 'chunk_size': 500, 'n_chunks': 1, 'bs': 48, 'workers': 8, 'valid_pct': 0.025, 'trf_dim': 512, 'trf_enc': 4, 'trf_dec': 4, 'trf_heads': 4, 'trf_do': 0.1, 'trf_act': 'gelu', 'lr': 0.003, 'clip': 0.0, 'moms': (0.95, 0.85, 0.95), 'epochs': 5, 'tfixup': True, 'mixup': False, 'opt': 'ranger_lamb', 'opt_kwargs': {}, 'fit': 'fit_flat_cos', 'fit_kwargs': {'pct_start': 0.5, 'div_final': 100.0}, 'fp16': 'to_fp16', 'loss': 'ce', 'wua': 0.0, 'pad': 'r', 'local_rank': None}\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1638222189602
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_gpus = torch.cuda.device_count() if H.local_rank is None else 1\n",
        "if H.local_rank is not None:\n",
        "    torch.cuda.set_device(H.local_rank)\n",
        "    torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
        "    print(f\"DISTRIBUTED: {H.local_rank}\")"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1638222190098
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read df and meta"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO detect if meta exists and don't load it."
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1638222190561
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(in_d / f'meta_v{H.data}.pkl', 'rb') as f:\n",
        "    meta = pickle.load(f)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1638222191008
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QCols = enum.IntEnum('QCols', meta.qcols, start=0)\n",
        "LCols = enum.IntEnum('LCols', meta.lcols, start=0)\n",
        "Cats  = enum.IntEnum('Cats',  meta.cat_names, start=0)\n",
        "Conts = enum.IntEnum('Conts', meta.cont_names, start=0)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1638222191440
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "with open(in_d / f'data_v{H.data}.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1638222428038
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO detect if data exists and don't load it."
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1638222428781
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del data.attempt_num_coo\n",
        "del data.attempts_correct_coo\n",
        "gc.collect()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "40"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1638222429271
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Y"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "lut = meta.icats['answered_correctly'],meta.icats['user_answer']\n",
        "y_d = {}\n",
        "for k, v in data.cat_d.items():\n",
        "    y_d[k] = np.column_stack((lut[0][v[:,Cats.answered_correctly] - 1],lut[1][v[:,Cats.user_answer] - 1]))"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1638222440022
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chop sequences"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def chop_sequence(d):\n",
        "    nv = defaultdict(dict)\n",
        "    for k, v in d.items():\n",
        "        i = 0\n",
        "        while i*H.chunk_size < len(v):\n",
        "            nv[k][i] = v[i*H.chunk_size:(i+1)*H.chunk_size]\n",
        "            i += 1\n",
        "    return nv"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1638222440495
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_d  = chop_sequence(data.cat_d)\n",
        "cont_d = chop_sequence(data.cont_d)\n",
        "tags_d = chop_sequence(data.tags_d)\n",
        "tagw_d = chop_sequence(data.tagw_d)\n",
        "y_d    = chop_sequence(y_d)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1638222452452
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#assert np.concatenate(list(cat_d.values())).shape[0] == np.concatenate(list(data.cat_d.values())).shape[0]"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1638222452997
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'There are {len(data.cat_d)} different users')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "There are 393656 different users\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1638222453655
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/valid split"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "group_keys = sorted(list(cat_d.keys()))"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1638222454133
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Last H.valid_pct is valid set\n",
        "train_group_keys = group_keys[:int((1 - H.valid_pct) * len(group_keys))]\n",
        "valid_group_keys = group_keys[int((1 - H.valid_pct) * len(group_keys)):]"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1638222454598
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'users: train={len(train_group_keys)}, valid={len(valid_group_keys)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "users: train=383814, valid=9842\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1638222455195
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To dicts"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dict(d, keys):\n",
        "    return { (u, t): d[u][t] for u in keys for t in d[u].keys() }"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1638222455688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_cat =  split_dict(cat_d, train_group_keys)\n",
        "train_x_cont = split_dict(cont_d, train_group_keys)\n",
        "train_x_tags = split_dict(tags_d, train_group_keys)\n",
        "train_x_tagw = split_dict(tagw_d, train_group_keys)\n",
        "train_y =      split_dict(y_d, train_group_keys)"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1638222456219
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_x_cat =  split_dict(cat_d, valid_group_keys)\n",
        "valid_x_cont = split_dict(cont_d, valid_group_keys)\n",
        "valid_x_tags = split_dict(tags_d, valid_group_keys)\n",
        "valid_x_tagw = split_dict(tagw_d, valid_group_keys)\n",
        "valid_y =      split_dict(y_d, valid_group_keys)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1638222456722
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'seqs: train={len(train_x_cat)}, valid={len(valid_x_cat)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "seqs: train=507050, valid=12914\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1638222457205
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class InteractionsDataset(Dataset):\n",
        "    def __init__(self, x_cat, x_cont, x_tags, x_tagw, y, minids=False):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.means = np.expand_dims(meta.means, axis=0) # ready to broadcast\n",
        "        self.stds  = np.expand_dims(meta.stds , axis=0)\n",
        "        \n",
        "        self.n_inp = 5  # number of feature (x) tensors\n",
        "        \n",
        "        self.x_cat = x_cat  # SL, XF (sequence len, feature columns) \n",
        "        self.x_cont = x_cont\n",
        "        self.x_tags = x_tags      \n",
        "        self.x_tagw = x_tagw\n",
        "        self.y = y  # SL, 1\n",
        "        \n",
        "        self.keys = list(self.x_cat.keys()) # list of group keys\n",
        "        \n",
        "        if minids:\n",
        "            self.keys = self.keys[:H.bs*2]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keys) # H.bs * 2\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user_id, time_slice = self.keys[idx]\n",
        "        win = range(max(0, time_slice - H.n_chunks + 1), time_slice + 1)\n",
        "        x_cat  = np.concatenate([ self.x_cat [(user_id, ts)] for ts in win ])\n",
        "        x_cont = np.concatenate([ self.x_cont[(user_id, ts)] for ts in win ])\n",
        "        x_tags = np.concatenate([ self.x_tags[(user_id, ts)] for ts in win ])\n",
        "        x_tagw = np.concatenate([ self.x_tagw[(user_id, ts)] for ts in win ])\n",
        "        y      = np.concatenate([ self.y     [(user_id, ts)] for ts in win ])\n",
        "        \n",
        "        pad = H.chunk_size * H.n_chunks - x_cat.shape[0]\n",
        "        \n",
        "        # Normalize x_cont\n",
        "        x_cont = (x_cont - self.means) / self.stds\n",
        "        x_cont[np.isnan(x_cont)] = 0\n",
        "        \n",
        "        padt = (0,pad) if H.pad == 'r' else (pad,0)\n",
        "        \n",
        "        x_mask = np.zeros(x_cat.shape[0], dtype=np.bool)\n",
        "        \n",
        "        x_mask = np.pad(x_mask, padt, constant_values=(True))\n",
        "        x_cat  = np.pad(x_cat , (padt, (0, 0)), constant_values=(0)).astype(np.int64)\n",
        "        x_cont = np.pad(x_cont, (padt, (0, 0)), constant_values=(0)).astype(np.float32)\n",
        "        x_tags = np.pad(x_tags, (padt, (0, 0)), constant_values=(0)).astype(np.int64)\n",
        "        x_tagw = np.pad(x_tagw, (padt, (0, 0)), constant_values=(0.)).astype(np.float32)\n",
        "        y      = np.pad(y,      (padt, (0, 0)), constant_values=(-1)).astype(np.int64)\n",
        "\n",
        "        return x_mask, x_cat, x_cont, x_tags, x_tagw, y"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1638222457943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = InteractionsDataset(train_x_cat, train_x_cont, train_x_tags, train_x_tagw, train_y)\n",
        "valid_ds = InteractionsDataset(valid_x_cat, valid_x_cont, valid_x_tags, valid_x_tagw, valid_y)"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1638222458442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_mask, x_cat, x_cont, x_tags, x_tagw, y = train_ds[0]"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1638222458908
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds.keys)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "507050"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1638222459455
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#x_tagw[-47:]"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1638222459943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert x_cat.shape == (H.chunk_size*H.n_chunks, len(meta.cat_names))\n",
        "assert x_cont.shape == (H.chunk_size*H.n_chunks, len(meta.cont_names))\n",
        "assert x_tags.shape == x_tagw.shape == (H.chunk_size*H.n_chunks, 6)\n",
        "assert y.shape == (H.chunk_size*H.n_chunks, 2)"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1638222460406
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, bs=H.bs, shuffle=True, drop_last=True, num_workers=H.workers)\n",
        "valid_dl = DataLoader(valid_ds, bs=H.bs,                               num_workers=H.workers)"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1638222460868
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls = DataLoaders(train_dl, valid_dl)"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1638222461346
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_mask,x_cat, x_cont, x_tags, x_tagw, y = dls.one_batch()"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1638222461856
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(precision=4, suppress=True)\n",
        "torch.set_printoptions(precision=4, linewidth=200, sci_mode=False)"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1638222465470
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_cont[1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "tensor([[-0.2928, -0.3581, -0.1834,  ..., -0.0769,  0.0000,  0.0000],\n        [-0.2928, -0.3581, -0.1834,  ..., -0.0766, -0.0428, -0.6855],\n        [-0.2928, -0.3581, -0.1834,  ..., -0.0763, -0.0428, -0.6399],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1638222465922
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_cat.shape, x_cont.shape, x_tags.shape, x_tagw.shape, y.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "(torch.Size([48, 500, 11]),\n torch.Size([48, 500, 23]),\n torch.Size([48, 500, 6]),\n torch.Size([48, 500, 6]),\n torch.Size([48, 500, 2]))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1638222466331
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert x_cat.isnan().any() == False\n",
        "assert x_cont.isnan().any() == False\n",
        "assert x_tags.isnan().any() == False\n",
        "assert x_tagw.isnan().any() == False"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1638222466678
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert x_cat.shape == (H.bs, H.chunk_size*H.n_chunks, len(meta.cat_names))\n",
        "assert x_cont.shape == (H.bs, H.chunk_size*H.n_chunks, len(meta.cont_names))\n",
        "assert x_tags.shape == x_tagw.shape == (H.bs, H.chunk_size*H.n_chunks, 6)\n",
        "assert y.shape == (H.bs, H.chunk_size*H.n_chunks, 2)"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1638222466990
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss and metrics"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def roc_auc(pred, targ):\n",
        "    pred = torch.softmax(pred, dim=2)\n",
        "    pred = pred[:,:,1:2] # prediction for True\n",
        "    idx = targ != -1\n",
        "    pred = pred[idx]\n",
        "    targ = targ[idx]\n",
        "    pred, targ = flatten_check(pred, targ)\n",
        "    if len(targ.unique()) == 2:\n",
        "        return roc_auc_score(targ.cpu().numpy(), pred.cpu().numpy())\n",
        "    else:\n",
        "        return 0"
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1638222467477
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss if H.loss=='ce' else globals()[H.loss]\n",
        "loss    = loss_fn(ignore_index=-1)\n",
        "loss_nr = loss_fn(ignore_index=-1, reduction='none')\n",
        "\n",
        "def loss_func(pred, targ, shuffle=None, lam=None):\n",
        "    b, s, l = pred.shape\n",
        "    if shuffle is not None:\n",
        "        targ_shuffled = targ[shuffle].view(b*s)\n",
        "    pred = pred.view(b*s, l)\n",
        "    targ = targ.view(b*s)\n",
        "\n",
        "    if shuffle is not None:\n",
        "        l0 = loss_nr(pred, targ).view(b, s)\n",
        "        l1 = loss_nr(pred, targ_shuffled).view(b, s)\n",
        "        return torch.lerp(l0, l1, lam.view(lam.shape[0], 1)).mean()\n",
        "    else:\n",
        "        #print(targ.unique()) # CUDA assert error if any index here is bigger than dimension l (labels) of pred\n",
        "        return loss(pred, targ)\n",
        "    \n",
        "def ua_loss_func(pred, targ, shuffle=None, lam=None):\n",
        "    loss_fn = loss_func\n",
        "    l = loss_fn(pred[...,:2],targ[...,:1],shuffle,lam) \n",
        "    if H.wua and targ.shape[-1]>1: l += H.wua * loss_fn(pred[...,2:],targ[...,1:],shuffle,lam)\n",
        "    return l"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1638222467792
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "_p = torch.zeros([32, 127, 6])\n",
        "_t = torch.empty ([32, 127,2]).type(torch.long)\n",
        "_t[...,0] = torch.randint(2,_t.shape[:2])\n",
        "_t[...,1] = torch.randint(4,_t.shape[:2])"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1638222468095
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "roc_auc(_p[...,:2], _t[...,:1])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "0.5"
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1638222468399
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "loss_func(_p[...,:2], _t[...,:1])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "tensor(0.6931)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1638222468782
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "ua_loss_func(_p, _t)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "tensor(0.6931)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1638222469093
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LBMetric(Metric):\n",
        "    def __init__(self, loss_func, name):\n",
        "        self.loss_func = loss_func\n",
        "        self.nam = name\n",
        "        \n",
        "    def reset(self):\n",
        "        self.targs, self.preds = [], []\n",
        "        \n",
        "    def accumulate(self, learn):\n",
        "        self.preds.append(learn.to_detach(learn.pred[...,:2]))\n",
        "        self.targs.append(learn.to_detach(learn.y[...,:1]))\n",
        "    \n",
        "    @property\n",
        "    def value(self):\n",
        "        if len(self.preds) == 0: return\n",
        "        preds = torch.cat(self.preds)\n",
        "        targs = torch.cat(self.targs)\n",
        "        r = self.loss_func(preds, targs)\n",
        "        return r\n",
        "    \n",
        "    @property\n",
        "    def name(self):\n",
        "        return self.nam"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1638222469378
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixup"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "lam = Beta(0.5, 0.5).sample((10000,))\n",
        "lam = torch.stack([lam, 1-lam], 1)\n",
        "lam = lam.max(1)[0].numpy()\n",
        "_ = plt.hist(lam, bins=100)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1638222469870
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMixUp(Callback):\n",
        "    run_after,run_valid = [Normalize],False\n",
        "    def __init__(self, alpha=0.4): \n",
        "        self.distrib = Beta(tensor(alpha), tensor(alpha))\n",
        "\n",
        "    def before_batch(self):\n",
        "        lam = self.distrib.sample((self.y.size(0),)).squeeze().to(self.y.device)\n",
        "        lam = torch.stack([lam, 1-lam], 1)\n",
        "        lam = lam.max(1)[0]\n",
        "        shuffle = torch.randperm(self.y.size(0)).to(self.y.device)\n",
        "        self.learn.xb = (*self.xb, shuffle, lam)\n",
        "        self.learn.yb = (*self.yb, shuffle, lam)"
      ],
      "outputs": [],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1638222470181
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GradientClipping(Callback):\n",
        "    \"Gradient clipping during training.\"\n",
        "    def __init__(self, clip:float = 0.):\n",
        "        self.clip = clip\n",
        "\n",
        "    def after_backward(self, **kwargs):\n",
        "        \"Clip the gradient before the optimizer step.\"\n",
        "        if self.clip: nn.utils.clip_grad_norm_(self.learn.model.parameters(), self.clip)"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1638222470520
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class TutorNet(nn.Module):\n",
        "    def __init__(self, emb_szs, tag_emb_szs, emb_do, n_cont, trf_dim, trf_enc, trf_dec, trf_heads, trf_do, trf_act):\n",
        "        super().__init__()\n",
        "        self.nhead,self.trf_dim = trf_heads, trf_dim\n",
        "        \n",
        "        tag_emb_szs =(tag_emb_szs[0]+1, trf_dim)\n",
        "\n",
        "        self.embeds    = nn.ModuleList([nn.Sequential(nn.Embedding(ni+1, nf, max_norm=1.),nn.Linear(nf, trf_dim)) \n",
        "                                        for ni, nf in emb_szs])\n",
        "        self.tagembeds = nn.EmbeddingBag(*tag_emb_szs, max_norm=1., mode='sum')\n",
        "        self.conts     = nn.Linear(n_cont, trf_dim)\n",
        "            \n",
        "        self.trafo = nn.Transformer(\n",
        "            d_model = trf_dim,\n",
        "            nhead = trf_heads,\n",
        "            num_encoder_layers = trf_enc,\n",
        "            num_decoder_layers = trf_dec,\n",
        "            dim_feedforward = trf_dim*4,\n",
        "            dropout = trf_do,\n",
        "            activation = trf_act,\n",
        "        )\n",
        "\n",
        "        self.mlp = nn.Linear(trf_dim, 6)\n",
        "        \n",
        "    def forward(self, x_mask, x_cat, x_cont, x_tags, x_tagw, shuffle=None, lam=None):\n",
        "        b, sl, catf, contf, tagsf = (*x_cat.shape, x_cont.shape[2], x_tags.shape[2])\n",
        "        \n",
        "        x_cat  += 1\n",
        "        x_tags += 1\n",
        "    \n",
        "        # compute masks\n",
        "        causal_mask  = torch.triu(torch.ones(1,sl, sl,dtype=torch.bool,device=x_cat.device), diagonal=1).expand(b,-1,-1)\n",
        "        x_tci   = x_cat[...,Cats.task_container_id]\n",
        "        x_tci_s = torch.zeros_like(x_tci)\n",
        "        x_tci_s[...,1:] = x_tci[...,:-1]\n",
        "        enc_container_aware_mask =  (x_tci.unsqueeze(-1) == x_tci_s.unsqueeze(-1).permute(0,2,1)) | causal_mask\n",
        "        dec_container_aware_mask = ~(x_tci.unsqueeze(-1) == x_tci.unsqueeze(-1).permute(0,2,1))   & causal_mask\n",
        "\n",
        "        padding_mask = x_mask \n",
        "                \n",
        "        # encoder x (shifted q & a)\n",
        "        enc_cat  = torch.zeros_like(x_cat)\n",
        "        enc_cont = torch.zeros_like(x_cont)\n",
        "        enc_tags = torch.zeros_like(x_tags)\n",
        "        enc_tagw = torch.zeros_like(x_tagw)\n",
        "        \n",
        "        enc_cat[:,1:]  = x_cat[:,:-1]\n",
        "        enc_cont[:,1:] = x_cont[:,:-1]\n",
        "        enc_tags[:,1:] = x_tags[:,:-1]\n",
        "        enc_tagw[:,1:] = x_tagw[:,:-1]\n",
        "        \n",
        "        # decoder x (nonshifted q)\n",
        "        dec_cat  = x_cat\n",
        "        dec_cont = x_cont\n",
        "        dec_tags = x_tags\n",
        "        dec_tagw = x_tagw\n",
        "\n",
        "        # hide correct answer and user answered correctly from decoder\n",
        "        dec_cat[...,Cats.answered_correctly] = 0\n",
        "        dec_cat[...,Cats.user_answer] = 0\n",
        "        dec_cat[...,Cats.qhe] = 0\n",
        "        dec_cont[...,Conts.qet] = 0\n",
        "        dec_cont[...,Conts.qet_log] = 0\n",
        "        \n",
        "        # print(enc_cont.shape)\n",
        "        enc_cat  =  enc_cat.view(b * sl, catf)   # b*sl, catf\n",
        "        enc_tags = enc_tags.view(b * sl, tagsf) # b*sl, tagsf\n",
        "        enc_tagw = enc_tagw.view(b * sl, tagsf) # b*sl, tagsf\n",
        "\n",
        "        dec_cat  =  dec_cat.view(b * sl, catf)   # b*sl, catf\n",
        "        dec_tags = dec_tags.view(b * sl, tagsf) # b*sl, tagsf\n",
        "        dec_tagw = dec_tagw.view(b * sl, tagsf) # b*sl, tagsf\n",
        "        \n",
        "        # embed categorical vars\n",
        "        enc = torch.mean(torch.stack([\n",
        "            *[ e(enc_cat[:,i]) for i, e in enumerate(self.embeds) ],\n",
        "            self.tagembeds(enc_tags, per_sample_weights=enc_tagw),\n",
        "            self.conts(enc_cont).view(-1,self.trf_dim)\n",
        "        ]),dim=0)\n",
        "        \n",
        "        dec = torch.mean(torch.stack([\n",
        "            *[ e(dec_cat[:,i]) for i, e in enumerate(self.embeds) ],\n",
        "            self.tagembeds(dec_tags, per_sample_weights=dec_tagw),\n",
        "            self.conts(dec_cont).view(-1,self.trf_dim)\n",
        "        ]),dim=0)\n",
        "        \n",
        "        enc = enc.view(b, sl, self.trf_dim)           # b, sl, sum of cat, cont and tag ftrs\n",
        "        dec = dec.view(b, sl, self.trf_dim)           # b, sl, sum of cat, cont and tag ftrs\n",
        "\n",
        "        if shuffle is not None:\n",
        "            enc = torch.lerp(enc, enc[shuffle], lam.view(lam.shape[0], 1, 1))\n",
        "            dec = torch.lerp(dec, dec[shuffle], lam.view(lam.shape[0], 1, 1))\n",
        "            padding_mask = None\n",
        "            enc_container_aware_mask = dec_container_aware_mask = causal_mask | causal_mask[shuffle]\n",
        "        \n",
        "        enc = enc.permute(1, 0, 2)          # sl, b, tf (torchformer input)\n",
        "        dec = dec.permute(1, 0, 2)          # sl, b, tf\n",
        "\n",
        "        expand_nheads = lambda t: t.unsqueeze(1).expand(t.shape[0],self.nhead,-1,-1).reshape(-1,*t.shape[-2:])\n",
        "        \n",
        "        o = self.trafo(\n",
        "            enc, \n",
        "            dec, \n",
        "            src_mask = expand_nheads(enc_container_aware_mask),\n",
        "            tgt_mask = expand_nheads(dec_container_aware_mask),\n",
        "            memory_mask = expand_nheads(enc_container_aware_mask),\n",
        "            src_key_padding_mask = padding_mask,\n",
        "            tgt_key_padding_mask = padding_mask,\n",
        "            memory_key_padding_mask = padding_mask,\n",
        "        )                                   # sl, b, tf\n",
        "        o = o.permute(1, 0, 2)              # b, sl, tf\n",
        "        o = self.mlp(o)                     # b, sl, of (of=2)\n",
        "        #print(o)\n",
        "        return o"
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1638222470923
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_szs = list(zip(meta.n_emb.values(), meta.emb_dim.values()))\n",
        "tag_emb_szs = meta.tags_n_emb, meta.tags_emb_dim"
      ],
      "outputs": [],
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1638222471238
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TutorNet(emb_szs, tag_emb_szs, None, len(meta.cont_names), \n",
        "                 H.trf_dim, H.trf_enc, H.trf_dec, H.trf_heads, H.trf_do, H.trf_act)"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1638222471563
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T-Fixup init\n",
        "\n",
        "1. Apply Xavier initialization for all parameters excluding input embeddings. Use Gaussian initialization $N(0,d^{-\\frac{1}{2}})$ for input embeddings where d is the embedding dimension.\n",
        "\n",
        "2. Scale $v_{d}$ and $w_{d}$ matrices in each decoder attention block, weight matrices in each decoder MLP block and input embeddings $x$ and $y$ in encoder and decoder by $(9N)^{−\\frac{1}{4}}$: [code](https://github.com/layer6ai-labs/T-Fixup/blob/f1fae213ce7b48829f81632d0c96bb039b7c450e/fairseq/modules/transformer_layer.py#L161), [code](https://github.com/layer6ai-labs/T-Fixup/blob/f1fae213ce7b48829f81632d0c96bb039b7c450e/fairseq/models/transformer.py#L378), [code](https://github.com/layer6ai-labs/T-Fixup/blob/f1fae213ce7b48829f81632d0c96bb039b7c450e/fairseq/models/transformer.py#L604)\n",
        "\n",
        "3. Scale $v_{e}$ and $w_{e}$ matrices in each encoder attention block and weight matrices in each encoder MLP block by $0.67N^{−\\frac{1}{4}}$: [code](https://github.com/layer6ai-labs/T-Fixup/blob/f1fae213ce7b48829f81632d0c96bb039b7c450e/fairseq/modules/transformer_layer.py#L36)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def trunc_normal_(x, mean=0., std=1.):\n",
        "    \"Truncated normal initialization (approximation)\"\n",
        "    # From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12\n",
        "    return x.normal_().fmod_(2).mul_(std).add_(mean)"
      ],
      "outputs": [],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1638222471959
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if H.tfixup:\n",
        "    for n,p in model.named_parameters():\n",
        "        if re.match(r'.*bias$|.*bn\\.weight$|.*norm.*\\.weight',n): continue\n",
        "        gain = 1.\n",
        "        if re.match(r'.*decoder.*',n): \n",
        "            gain = (9*H.trf_dec)**(-1./4.)\n",
        "            if re.match(f'.*in_proj_weight$',n): gain *= (2**0.5)\n",
        "        elif re.match(r'.*encoder.*',n): \n",
        "            gain = 0.67*(H.trf_enc**(-1./4.))\n",
        "            if re.match(f'.*in_proj_weight$',n): gain *= (2**0.5)\n",
        "        if re.match(r'^embeds|^tagembeds', n): \n",
        "            trunc_normal_(p.data,std=(4.5*(H.trf_enc+H.trf_dec))**(-1./4.)*H.trf_dim**(-0.5))\n",
        "        else:                                  \n",
        "            nn.init.xavier_normal_(p,gain=gain)"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1638222472291
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if H.tfixup:\n",
        "    class MyModelPatcher(ModelPatcher):\n",
        "        def new_child_module(self, child_module_name, child_module, patch_info): return nn.Identity()\n",
        "    mp = MyModelPatcher()\n",
        "    mp.add_pattern(r\".*norm\\d?.*\",{})\n",
        "    mp.patch_model(model)"
      ],
      "outputs": [],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1638222472617
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 56,
          "data": {
            "text/plain": "TutorNet(\n  (embeds): ModuleList(\n    (0): Sequential(\n      (0): Embedding(3, 1, max_norm=1.0)\n      (1): Linear(in_features=1, out_features=512, bias=True)\n    )\n    (1): Sequential(\n      (0): Embedding(5, 3, max_norm=1.0)\n      (1): Linear(in_features=3, out_features=512, bias=True)\n    )\n    (2): Sequential(\n      (0): Embedding(9767, 274, max_norm=1.0)\n      (1): Linear(in_features=274, out_features=512, bias=True)\n    )\n    (3): Sequential(\n      (0): Embedding(6, 4, max_norm=1.0)\n      (1): Linear(in_features=4, out_features=512, bias=True)\n    )\n    (4): Sequential(\n      (0): Embedding(420, 47, max_norm=1.0)\n      (1): Linear(in_features=47, out_features=512, bias=True)\n    )\n    (5): Sequential(\n      (0): Embedding(9, 5, max_norm=1.0)\n      (1): Linear(in_features=5, out_features=512, bias=True)\n    )\n    (6): Sequential(\n      (0): Embedding(4, 3, max_norm=1.0)\n      (1): Linear(in_features=3, out_features=512, bias=True)\n    )\n    (7): Sequential(\n      (0): Embedding(13525, 329, max_norm=1.0)\n      (1): Linear(in_features=329, out_features=512, bias=True)\n    )\n    (8): Sequential(\n      (0): Embedding(10002, 278, max_norm=1.0)\n      (1): Linear(in_features=278, out_features=512, bias=True)\n    )\n    (9): Sequential(\n      (0): Embedding(6, 4, max_norm=1.0)\n      (1): Linear(in_features=4, out_features=512, bias=True)\n    )\n    (10): Sequential(\n      (0): Embedding(7, 4, max_norm=1.0)\n      (1): Linear(in_features=4, out_features=512, bias=True)\n    )\n  )\n  (tagembeds): EmbeddingBag(190, 512, max_norm=1.0, mode=sum)\n  (conts): Linear(in_features=23, out_features=512, bias=True)\n  (trafo): Transformer(\n    (encoder): TransformerEncoder(\n      (layers): ModuleList(\n        (0): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (norm1): Identity()\n          (norm2): Identity()\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n        (1): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (norm1): Identity()\n          (norm2): Identity()\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n        (2): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (norm1): Identity()\n          (norm2): Identity()\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n        (3): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (norm1): Identity()\n          (norm2): Identity()\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (norm): Identity()\n    )\n    (decoder): TransformerDecoder(\n      (layers): ModuleList(\n        (0): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (multihead_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (norm1): Identity()\n          (norm2): Identity()\n          (norm3): Identity()\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n          (dropout3): Dropout(p=0.1, inplace=False)\n        )\n        (1): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (multihead_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (norm1): Identity()\n          (norm2): Identity()\n          (norm3): Identity()\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n          (dropout3): Dropout(p=0.1, inplace=False)\n        )\n        (2): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (multihead_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (norm1): Identity()\n          (norm2): Identity()\n          (norm3): Identity()\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n          (dropout3): Dropout(p=0.1, inplace=False)\n        )\n        (3): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (multihead_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n          (norm1): Identity()\n          (norm2): Identity()\n          (norm3): Identity()\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n          (dropout3): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (norm): Identity()\n    )\n  )\n  (mlp): Linear(in_features=512, out_features=6, bias=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1638222473030
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls = dls.cuda()\n",
        "model = model.cuda()"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1638222479497
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@delegates(Lamb)\n",
        "def ranger_lamb(p, lr, mom=0.95, wd=0.01, eps=1e-6, **kwargs):\n",
        "    return Lookahead(Lamb(p, lr=lr, mom=mom, wd=wd, eps=eps, **kwargs))"
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {
        "gather": {
          "logged": 1638222479871
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(\n",
        "    dls,\n",
        "    model,\n",
        "    loss_func=ua_loss_func,\n",
        "    opt_func=partial(globals()[H.opt],**H.opt_kwargs),\n",
        "    moms = H.moms,\n",
        "    metrics=[\n",
        "        LBMetric(loss_func, 'acc_valid_loss'),\n",
        "        LBMetric(roc_auc, 'acc_roc_auc'),\n",
        "    ],\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1638222480236
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_fp16 = getattr(learn,H.fp16,None)\n",
        "if f_fp16: f_fp16()"
      ],
      "outputs": [],
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1638222480543
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rank0_only(func, *args, **kwargs):\n",
        "    \"Execute `func` in the Rank-0 process first, then in other ranks in parallel.\"\n",
        "    if args or kwargs: func = partial(func, *args, **kwargs)\n",
        "    dummy_l = Learner(DataLoaders(device='cpu'), nn.Linear(1,1), loss_func=lambda: 0)\n",
        "    res = None\n",
        "    with dummy_l.distrib_ctx():\n",
        "        if not rank_distrib(): res = func()\n",
        "        distrib_barrier()\n",
        "    return res"
      ],
      "outputs": [],
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1638222480851
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@patch\n",
        "def load(learn:Learner,fn,with_opt=False):\n",
        "    def __inner(learn:Learner,fn,with_opt=False):\n",
        "        m_dict = torch.load(f\"{(Path(learn.model_dir) / fn)}.pth\")#['model']\n",
        "        ks = []\n",
        "        for attempts in range(2):\n",
        "            try:\n",
        "                res = learn.model.load_state_dict(m_dict,strict=False)\n",
        "                print(f\"Loaded {fn} ignoring: {' '.join(ks)} and {res}\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                for k in [m[1] for m in [re.match(r\"^.*mismatch for ([\\w\\.]+):\",l) for l in str(e).split(\"\\n\")] if m is not None]:\n",
        "                    m_dict.pop(k,None)\n",
        "                    ks.append(k)\n",
        "        return learn\n",
        "    return rank0_only(__inner, learn, fn, with_opt)"
      ],
      "outputs": [],
      "execution_count": 62,
      "metadata": {
        "gather": {
          "logged": 1638222481471
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "if H.load:\n",
        "    learn.load(H.load, with_opt=False)\n",
        "    print(f\"Loaded: {H.load}\")"
      ],
      "outputs": [],
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1638222481806
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if H.clip: \n",
        "    learn.add_cb(GradientClipping(H.clip))\n",
        "    print('clip on')"
      ],
      "outputs": [],
      "execution_count": 64,
      "metadata": {
        "gather": {
          "logged": 1638222482189
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if H.local_rank is not None: \n",
        "    learn.to_distributed(H.local_rank)\n",
        "    print('local_rank on')\n",
        "if H.mixup: \n",
        "    learn.add_cb(MyMixUp(0.5))\n",
        "    print('mixup on')"
      ],
      "outputs": [],
      "execution_count": 65,
      "metadata": {
        "gather": {
          "logged": 1638222482567
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if H.validate:\n",
        "    res = learn.validate()\n",
        "    print(f\"CV: {res[-1]}\")"
      ],
      "outputs": [],
      "execution_count": 66,
      "metadata": {
        "gather": {
          "logged": 1638222483088
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "learn.summary()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "text/plain": "TutorNet (Input shape: 48 x 500)\n============================================================================\nLayer (type)         Output Shape         Param #    Trainable \n============================================================================\n                     48 x 1              \nEmbedding                                 3          True      \n____________________________________________________________________________\n                     48 x 512            \nLinear                                    1024       True      \n____________________________________________________________________________\n                     48 x 3              \nEmbedding                                 15         True      \n____________________________________________________________________________\n                     48 x 512            \nLinear                                    2048       True      \n____________________________________________________________________________\n                     48 x 274            \nEmbedding                                 2676158    True      \n____________________________________________________________________________\n                     48 x 512            \nLinear                                    140800     True      \n____________________________________________________________________________\n                     48 x 4              \nEmbedding                                 24         True      \n____________________________________________________________________________\n                     48 x 512            \nLinear                                    2560       True      \n____________________________________________________________________________\n                     48 x 47             \nEmbedding                                 19740      True      \n____________________________________________________________________________\n                     48 x 512            \nLinear                                    24576      True      \n____________________________________________________________________________\n                     48 x 5              \nEmbedding                                 45         True      \n____________________________________________________________________________\n                     48 x 512            \nLinear                                    3072       True      \n____________________________________________________________________________\n                     48 x 3              \nEmbedding                                 12         True      \n____________________________________________________________________________\n                     48 x 512            \nLinear                                    2048       True      \n____________________________________________________________________________\n                     48 x 329            \nEmbedding                                 4449725    True      \n____________________________________________________________________________\n                     48 x 512            \nLinear                                    168960     True      \n____________________________________________________________________________\n                     48 x 278            \nEmbedding                                 2780556    True      \n____________________________________________________________________________\n                     48 x 512            \nLinear                                    142848     True      \n____________________________________________________________________________\n                     48 x 4              \nEmbedding                                 24         True      \n____________________________________________________________________________\n                     48 x 512            \nLinear                                    2560       True      \n____________________________________________________________________________\n                     48 x 4              \nEmbedding                                 28         True      \n____________________________________________________________________________\n                     48 x 512            \nLinear                                    2560       True      \nEmbeddingBag                              97280      True      \n____________________________________________________________________________\n                     48 x 500 x 512      \nLinear                                    12288      True      \n____________________________________________________________________________\n                     48 x 1 x 2048       \nLinear                                    1050624    True      \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 512        \nLinear                                    1049088    True      \nIdentity                                                       \nIdentity                                                       \nDropout                                                        \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 2048       \nLinear                                    1050624    True      \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 512        \nLinear                                    1049088    True      \nIdentity                                                       \nIdentity                                                       \nDropout                                                        \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 2048       \nLinear                                    1050624    True      \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 512        \nLinear                                    1049088    True      \nIdentity                                                       \nIdentity                                                       \nDropout                                                        \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 2048       \nLinear                                    1050624    True      \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 512        \nLinear                                    1049088    True      \nIdentity                                                       \nIdentity                                                       \nDropout                                                        \nDropout                                                        \nIdentity                                                       \n____________________________________________________________________________\n                     48 x 1 x 2048       \nLinear                                    1050624    True      \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 512        \nLinear                                    1049088    True      \nIdentity                                                       \nIdentity                                                       \nIdentity                                                       \nDropout                                                        \nDropout                                                        \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 2048       \nLinear                                    1050624    True      \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 512        \nLinear                                    1049088    True      \nIdentity                                                       \nIdentity                                                       \nIdentity                                                       \nDropout                                                        \nDropout                                                        \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 2048       \nLinear                                    1050624    True      \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 512        \nLinear                                    1049088    True      \nIdentity                                                       \nIdentity                                                       \nIdentity                                                       \nDropout                                                        \nDropout                                                        \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 2048       \nLinear                                    1050624    True      \nDropout                                                        \n____________________________________________________________________________\n                     48 x 1 x 512        \nLinear                                    1049088    True      \nIdentity                                                       \nIdentity                                                       \nIdentity                                                       \nDropout                                                        \nDropout                                                        \nDropout                                                        \nIdentity                                                       \n____________________________________________________________________________\n                     48 x 500 x 6        \nLinear                                    3078       True      \n____________________________________________________________________________\n\nTotal params: 27,329,728\nTotal trainable params: 27,329,728\nTotal non-trainable params: 0\n\nOptimizer used: functools.partial(<function ranger_lamb at 0x7f4ef40e9310>)\nLoss function: <function ua_loss_func at 0x7f4ef8276160>\n\nCallbacks:\n  - TrainEvalCallback\n  - MixedPrecision\n  - Recorder\n  - ProgressCallback"
          },
          "metadata": {}
        }
      ],
      "execution_count": 67,
      "metadata": {
        "gather": {
          "logged": 1638222485016
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "#learn.lr_find()"
      ],
      "outputs": [],
      "execution_count": 68,
      "metadata": {
        "gather": {
          "logged": 1638222485391
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "#learn.recorder.plot_lr_find(skip_end=10)"
      ],
      "outputs": [],
      "execution_count": 69,
      "metadata": {
        "gather": {
          "logged": 1638222485744
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#short_cb = learn.add_cb(ShortEpochCallback(pct=0.001))"
      ],
      "outputs": [],
      "execution_count": 70,
      "metadata": {
        "gather": {
          "logged": 1638222486069
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn.add_cb(SaveModelCallback(monitor='acc_roc_auc', comp=np.greater, fname=f'best{H.model}'))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 71,
          "data": {
            "text/plain": "<fastai.learner.Learner at 0x7f4ef415dc70>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1638222486459
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(H.fit, H.epochs, H.lr, H.fit_kwargs)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit_flat_cos 5 0.003 {'pct_start': 0.5, 'div_final': 100.0}\n"
        }
      ],
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1638222486746
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "syn_learn = synth_learner()\n",
        "getattr(syn_learn,H.fit)(H.epochs, H.lr,**H.fit_kwargs)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>17.660828</td>\n      <td>10.589945</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>12.318185</td>\n      <td>2.498382</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>7.896964</td>\n      <td>0.196060</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.316852</td>\n      <td>0.009770</td>\n      <td>00:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3.789580</td>\n      <td>0.010318</td>\n      <td>00:00</td>\n    </tr>\n  </tbody>\n</table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1638222488701
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "syn_learn.recorder.plot_sched()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1638222489013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 75,
          "data": {
            "text/plain": "- model: 210105\n- data: 210101b\n- load: None\n- validate: False\n- chunk_size: 500\n- n_chunks: 1\n- bs: 48\n- workers: 8\n- valid_pct: 0.025\n- trf_dim: 512\n- trf_enc: 4\n- trf_dec: 4\n- trf_heads: 4\n- trf_do: 0.1\n- trf_act: gelu\n- lr: 0.003\n- clip: 0.0\n- moms: (0.95, 0.85, 0.95)\n- epochs: 5\n- tfixup: True\n- mixup: False\n- opt: ranger_lamb\n- opt_kwargs: \n\n- fit: fit_flat_cos\n- fit_kwargs: \n  - pct_start: 0.5\n  - div_final: 100.0\n- fp16: to_fp16\n- loss: ce\n- wua: 0.0\n- pad: r\n- local_rank: None",
            "text/markdown": "- model: 210105\n- data: 210101b\n- load: None\n- validate: False\n- chunk_size: 500\n- n_chunks: 1\n- bs: 48\n- workers: 8\n- valid_pct: 0.025\n- trf_dim: 512\n- trf_enc: 4\n- trf_dec: 4\n- trf_heads: 4\n- trf_do: 0.1\n- trf_act: gelu\n- lr: 0.003\n- clip: 0.0\n- moms: (0.95, 0.85, 0.95)\n- epochs: 5\n- tfixup: True\n- mixup: False\n- opt: ranger_lamb\n- opt_kwargs: \n\n- fit: fit_flat_cos\n- fit_kwargs: \n  - pct_start: 0.5\n  - div_final: 100.0\n- fp16: to_fp16\n- loss: ce\n- wua: 0.0\n- pad: r\n- local_rank: None"
          },
          "metadata": {}
        }
      ],
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1638222489412
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#learn.fit_flat_cos(H.epochs, H.lr,**H.fit_kwargs)"
      ],
      "outputs": [],
      "execution_count": 76,
      "metadata": {
        "gather": {
          "logged": 1638222489728
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Fitting {H.local_rank}\")\n",
        "getattr(learn,H.fit)(H.epochs, H.lr,**H.fit_kwargs)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Fitting None\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>acc_valid_loss</th>\n      <th>acc_roc_auc</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.514199</td>\n      <td>0.515947</td>\n      <td>0.511980</td>\n      <td>0.792566</td>\n      <td>1:01:00</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.512181</td>\n      <td>0.510179</td>\n      <td>0.506200</td>\n      <td>0.798173</td>\n      <td>1:01:07</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.506178</td>\n      <td>0.506629</td>\n      <td>0.502587</td>\n      <td>0.801687</td>\n      <td>1:01:07</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.497723</td>\n      <td>0.501662</td>\n      <td>0.497615</td>\n      <td>0.806268</td>\n      <td>1:01:00</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.498730</td>\n      <td>0.499227</td>\n      <td>0.495168</td>\n      <td>0.808513</td>\n      <td>1:01:01</td>\n    </tr>\n  </tbody>\n</table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Better model found at epoch 0 with acc_roc_auc value: 0.7925662650799231.\nBetter model found at epoch 1 with acc_roc_auc value: 0.7981725037889048.\nBetter model found at epoch 2 with acc_roc_auc value: 0.801686915579876.\nBetter model found at epoch 3 with acc_roc_auc value: 0.8062679882633591.\nBetter model found at epoch 4 with acc_roc_auc value: 0.8085134053757371.\nLoaded best210105 ignoring:  and <All keys matched successfully>\n"
        }
      ],
      "execution_count": 77,
      "metadata": {
        "gather": {
          "logged": 1638240814371
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "learn.recorder.values"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 78,
          "data": {
            "text/plain": "[(#4) [0.5141985416412354,0.5159472823143005,0.5119799971580505,0.7925662650799231],\n (#4) [0.5121811032295227,0.5101794004440308,0.5061998963356018,0.7981725037889048],\n (#4) [0.506178081035614,0.5066288709640503,0.5025873184204102,0.801686915579876],\n (#4) [0.49772289395332336,0.5016622543334961,0.49761462211608887,0.8062679882633591],\n (#4) [0.49872997403144836,0.49922677874565125,0.49516764283180237,0.8085134053757371]]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 78,
      "metadata": {
        "gather": {
          "logged": 1638240814665
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#noexport\n",
        "learn.recorder.plot_loss()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAn10lEQVR4nO3deXxV1b338c8v8wAhzFOAgFIVEBCQgqLizOTQVnuxeu3j016q1jp0Eutja1tt6fW29z51KA9tve29VbGCVi4gSlWkDligIgQUGQQJQQlDAplzkvX8cXZOzjk5IQdIcsLO9/165ZW91157n99i+K21195nb3POISIi/pWU6ABERKRtKdGLiPicEr2IiM8p0YuI+JwSvYiIz6UkOoBYevXq5fLz8xMdhojIKWP9+vUHnHO9Y23rkIk+Pz+fdevWJToMEZFThpntbm6bpm5ERHxOiV5ExOeU6EVEfK5DztGLiByP2tpaCgsLqaqqSnQobS4jI4O8vDxSU1Pj3keJXkROeYWFhXTt2pX8/HzMLNHhtBnnHAcPHqSwsJChQ4fGvZ+mbkTklFdVVUXPnj19neQBzIyePXse95mLEr2I+ILfk3yDE2mnrxL9o69u442PihMdhohIh+KrRP/Eqh28tf1AosMQkU6mpKSEJ5544rj3mzFjBiUlJa0fUBRfJXoIXqwQEWlPzSX6urq6Y+63fPlycnNz2yiqRr6666aTTNGJSAczd+5cduzYwdixY0lNTaVLly7079+fDRs2sGXLFq699lr27NlDVVUVd911F3PmzAEaH/dSVlbG9OnTmTJlCm+//TYDBw7kxRdfJDMzs1Xi81WiB9CAXqRz+/H/bGZL0ZFWPeaIATn86KqRzW6fN28eBQUFbNiwgVWrVjFz5kwKCgpCt0A++eST9OjRg8rKSs4991y+9KUv0bNnz4hjbNu2jWeeeYbf/va3fPnLX2bx4sXcdNNNrRK/rxK9AcrzIpJoEydOjLjP/de//jUvvPACAHv27GHbtm1NEv3QoUMZO3YsAOPHj2fXrl2tFo+/Er3mbkQ6vWONvNtLdnZ2aHnVqlX89a9/5Z133iErK4upU6fGvA8+PT09tJycnExlZWWrxePDi7GJjkBEOpuuXbty9OjRmNtKS0vp3r07WVlZfPjhh6xZs6ado/PbiD7RAYhIp9SzZ0/OP/98Ro0aRWZmJn379g1tmzZtGvPnz2f06NGcccYZTJo0qd3j81WiB3CapReRBHj66adjlqenp/PSSy/F3NYwD9+rVy8KCgpC5d/97ndbNTZ/Td1oSC8i0kRcid7MppnZVjPbbmZzY2z/nplt8H4KzKzOzHp423aZ2SZvW5u/H1Bz9CIikVqcujGzZOBx4HKgEFhrZkucc1sa6jjnHgEe8epfBdzjnDsUdpiLnXNt/mwCDehFRJqKZ0Q/EdjunNvpnKsBFgLXHKP+DcAzrRGciIicvHgS/UBgT9h6oVfWhJllAdOAxWHFDnjFzNab2ZzmPsTM5pjZOjNbV1x8Yk+gNDM960ZEJEo8iT7WjEhz2fQq4K2oaZvznXPjgOnAN83swlg7OucWOOcmOOcm9O7dO46wYgSquRsRkSbiSfSFwKCw9TygqJm6s4matnHOFXm/9wMvEJwKajMaz4vIqaBLly4AFBUVcd1118WsM3XqVNatO/l7WOJJ9GuB4WY21MzSCCbzJdGVzKwbcBHwYlhZtpl1bVgGrgAKovdtLRrQi8ipZsCAASxatKhNP6PFu26ccwEzuwN4GUgGnnTObTazW73t872qXwBecc6Vh+3eF3jBewZNCvC0c25FazagabxteXQRkdjuvfdehgwZwu233w7Agw8+iJmxevVqDh8+TG1tLQ899BDXXBN5L8uuXbuYNWsWBQUFVFZWcsstt7BlyxbOOuusVnveTVzfjHXOLQeWR5XNj1r/A/CHqLKdwJiTivA46KFmIsJLc+HTTa17zH5nw/R5x6wye/Zs7r777lCi//Of/8yKFSu45557yMnJ4cCBA0yaNImrr7662Vz1m9/8hqysLDZu3MjGjRsZN25cq4SvRyCIiLSCc845h/3791NUVERxcTHdu3enf//+3HPPPaxevZqkpCT27t3LZ599Rr9+/WIeY/Xq1dx5550AjB49mtGjR7dKbL5K9IambkQ6vRZG3m3puuuuY9GiRXz66afMnj2bp556iuLiYtavX09qair5+fkxH1Ecri1mJnz1rBvN3IhIIs2ePZuFCxeyaNEirrvuOkpLS+nTpw+pqam8/vrr7N69+5j7X3jhhTz11FMAFBQUsHHjxlaJy1cjetDtlSKSOCNHjuTo0aMMHDiQ/v37c+ONN3LVVVcxYcIExo4dy5lnnnnM/W+77TZuueUWRo8ezdixY5k4sXXuRvdZoteQXkQSa9OmxgvBvXr14p133olZr6ysDAi+ILzhEcWZmZksXLiw1WPy1dQNaI5eRCSarxK95uhFRJryVaIP0pBepDPqLA80PJF2+irRa0Av0jllZGRw8OBB3yd75xwHDx4kIyPjuPbz2cVYzdGLdEZ5eXkUFhZyoo84P5VkZGSQl5d3XPv4KtGbKdGLdEapqakMHTo00WF0WD6butHkjYhINF8letCzbkREovkq0ev2ShGRpnyV6EFz9CIi0XyV6DWgFxFpyleJHvR1KRGRaL5K9HrDlIhIU75K9KA5ehGRaP5L9Jq8ERGJ4KtEr5kbEZGmfJXoAV2NFRGJ4qtErxG9iEhTvkr0oAG9iEg0XyV6PdRMRKQpXyV66DxvmRERiZevEr2Zpm5ERKLFlejNbJqZbTWz7WY2N8b275nZBu+nwMzqzKxHPPu2Jk3ciIg01WKiN7Nk4HFgOjACuMHMRoTXcc494pwb65wbC9wHvOGcOxTPvq1NMzciIpHiGdFPBLY753Y652qAhcA1x6h/A/DMCe57UvSsGxGRpuJJ9AOBPWHrhV5ZE2aWBUwDFp/AvnPMbJ2ZrTuZF/xqQC8iEimeRB9rmNxcPr0KeMs5d+h493XOLXDOTXDOTejdu3ccYTWl8byISFPxJPpCYFDYeh5Q1Ezd2TRO2xzvvq1Ct1eKiESKJ9GvBYab2VAzSyOYzJdEVzKzbsBFwIvHu2+r0ZBeRKSJlJYqOOcCZnYH8DKQDDzpnNtsZrd62+d7Vb8AvOKcK29p39ZuRES8bXlwEZFTUIuJHsA5txxYHlU2P2r9D8Af4tm3rRgo04uIRPHZN2M1dyMiEs1XiR70hikRkWi+SvQaz4uINOWrRA96BIKISDRfJXpN0YuINOWrRA8a0YuIRPNVotcbpkREmvJVogfddSMiEs1Xid5MUzciItF8lehFRKQp3yV6DehFRCL5KtHrEQgiIk35KtGD5uhFRKL5KtFrPC8i0pSvEn2QhvQiIuF8leh1e6WISFO+S/QiIhLJV4keNHEjIhLNV4lez7oREWnKV4kewGmSXkQkgq8SveboRUSa8lWiB83Ri4hE81Wi14BeRKQpXyV60H30IiLR/JXozTR1IyISxVeJXlM3IiJN+SrRg26vFBGJFleiN7NpZrbVzLab2dxm6kw1sw1mttnM3ggr32Vmm7xt61or8NgxtOXRRUROTSktVTCzZOBx4HKgEFhrZkucc1vC6uQCTwDTnHOfmFmfqMNc7Jw70HphNxMruhgrIhItnhH9RGC7c26nc64GWAhcE1XnK8DzzrlPAJxz+1s3zPikJCVRV69MLyISLp5EPxDYE7Ze6JWF+xzQ3cxWmdl6M7s5bJsDXvHK5zT3IWY2x8zWmdm64uLieOOPkJxkBOrrT2hfERG/anHqhtg3s0QPm1OA8cClQCbwjpmtcc59BJzvnCvypnNWmtmHzrnVTQ7o3AJgAcCECRNOaFiekmxUBTSiFxEJF8+IvhAYFLaeBxTFqLPCOVfuzcWvBsYAOOeKvN/7gRcITgW1iZQkI1CnRC8iEi6eRL8WGG5mQ80sDZgNLImq8yJwgZmlmFkW8HngAzPLNrOuAGaWDVwBFLRe+JFSkpMIaI5eRCRCi1M3zrmAmd0BvAwkA0865zab2a3e9vnOuQ/MbAWwEagHfuecKzCzYcALFrzvMQV42jm3os0ak2QE6jRHLyISLp45epxzy4HlUWXzo9YfAR6JKtuJN4XTHlKSddeNiEg0X30zNiXJqNVdNyIiEXyV6JPMqAko0YuIhItr6uZUsXRjEdVK9CIiEXw1or/kzOgnL4iIiK8S/dBe2aQk6clmIiLhfJXok8wI1DvN04uIhPFVon/s9e0AvPvxwQRHIiLScfgq0Tf427Y2fyKyiMgpw1eJfkT/HACOVgUSHImISMfhq0T/o6tGADBrdP8ERyIi0nH4KtGnpgSbU6Pn3YiIhPgq0WekJANQXVuX4EhERDoOXyX69NRgc/TtWBGRRr5K9BmpwRF9lUb0IiIhvkr06d4cfeHhygRHIiLScfgq0ScFX3DCo69tT3AkIiIdh68SfXZ6cqJDEBHpcHyV6NOSfdUcEZFW4avM6L2bVkREwvgq0YuISFNK9CIiPqdELyLic0r0IiI+p0QvIuJzSvQiIj6nRC8i4nNK9CIiPhdXojezaWa21cy2m9ncZupMNbMNZrbZzN44nn1FRKTtpLRUwcySgceBy4FCYK2ZLXHObQmrkws8AUxzzn1iZn3i3VdERNpWPCP6icB259xO51wNsBC4JqrOV4DnnXOfADjn9h/HviIi0obiSfQDgT1h64VeWbjPAd3NbJWZrTezm49jXwDMbI6ZrTOzdcXFxfFFLyIiLWpx6gaI9aQwF+M444FLgUzgHTNbE+e+wULnFgALACZMmBCzjoiIHL94En0hMChsPQ8oilHngHOuHCg3s9XAmDj3FRGRNhTP1M1aYLiZDTWzNGA2sCSqzovABWaWYmZZwOeBD+LcV0RE2lCLI3rnXMDM7gBeBpKBJ51zm83sVm/7fOfcB2a2AtgI1AO/c84VAMTat43aEqG2rp5UvYhERCSuqRucc8uB5VFl86PWHwEeiWff9lBaWUuvLunt/bEiIh2Ob4e8B8tqEh2CiEiH4ONEX53oEEREOgT/JvpyjehFRMDPiV4jehERwM+JXiN6ERHAh4m+Z3YaoEQvItLAd4k+PSXYpI+LyxMciYhIx+C7RP/YjeMA+NqUoQmORESkY/Bdos/JSAVg/1FdjBURAR8m+rr64IMvf/nK1gRHIiLSMfgu0ef3ygLgn84d1EJNEZHOwXeJPs17kNkTq3YkOBIRkY7Bd4neLNa7TkREOi/fJXoREYnk60RfURNIdAgiIgnn60Q/4ocvJzoEEZGE83WiFxGRTpDoD+uZNyLSyfky0f/u5gmh5XN+ujKBkYiIJJ4vE/1lI/omOgQRkQ7Dl4k+2q9f3cbmotJEhyEikhC+TfTfvPi00PKvVn7EzF+/Sf7cZWzffzSBUYmItD/fJvrvXXlmzPLLfrW6nSMREUks3yZ6gAHdMhIdgohIwvk60f/si2fHLC/Yq/l6Eek8fJ3oLxzeO2b5rEff5JDurxeRTsLXiT4pqfknWY776UqqauvaMRoRkcSIK9Gb2TQz22pm281sboztU82s1Mw2eD8/DNu2y8w2eeXrWjP4eDx07SieuHEcu+bNbLLtT2t2t3c4IiLtLqWlCmaWDDwOXA4UAmvNbIlzbktU1b8552Y1c5iLnXMHTi7UE3PTpCHNbvv3lR/x9QuGtWM0IiLtL54R/URgu3Nup3OuBlgIXNO2YbWNTQ9ewTcubEzs5TWauhER/4sn0Q8E9oStF3pl0Sab2ftm9pKZjQwrd8ArZrbezOY09yFmNsfM1pnZuuLi4riCP15dM1K5b8ZZbH94OgCDe2S1yeeIiHQkLU7dALGuaLqo9X8AQ5xzZWY2A/gLMNzbdr5zrsjM+gArzexD51yTby055xYACwAmTJgQffxWleK9V/aTQxVt+TEiIh1CPCP6QmBQ2HoeUBRewTl3xDlX5i0vB1LNrJe3XuT93g+8QHAqSERE2kk8iX4tMNzMhppZGjAbWBJewcz6mfdWbjOb6B33oJllm1lXrzwbuAIoaM0GiIjIsbU4deOcC5jZHcDLQDLwpHNus5nd6m2fD1wH3GZmAaASmO2cc2bWF3jB6wNSgKedcyvaqC0iIhJDPHP0DdMxy6PK5octPwY8FmO/ncCYk4yxTX18oJyhvbITHYaISJvx9Tdjj6VbZioAS98vaqGmiMiprdMm+noXvLHnlys/SnAkIiJtq9Mm+gdmjUh0CCIi7aLTJvrJw3qGlvPnLiNQV5/AaERE2k6nTfSDor4Ve/ezG1i761CCohERaTudNtFHW7pxH9fPfyfRYYiItDol+hi27y8jf+4yNuwpSXQoIiInrVMn+hsmDmpSlj93GZf96g0Avvfc+wDU1zuca9PH74iItJlOneh//sXRvPG9qc1u37a/jLsWvsewHyxn6H0R3xejJlBPeXWgjSMUETl5nTrRAwzpmc0VI/o2u/3FDY1fqMqfu4x7F20E4Pr5bzPyRy+3eXwiIifLOuKUxIQJE9y6de371sH1uw/zpd+8fdz7DeudzfjB3Xnk+uCTHgJ19aHHIB8qr6E6UEf/bpmtGquISDQzW++cmxBrW6cf0TcYNziXb1582nHvt7O4nOfWF1JeHeDrf1zL6fe/xG1/Wh885k9XMvnnr4Xq1upefRFJAI3oozy3bg9VgXoe+EvrPU05v2cWtXWOvSWV/OJLZ/NP5w5ucR/nHPUOkpNivfdFRCSSRvTH4foJg/jnSUP4r/8d+X6UM/t1PeFj7jpYwd6SSgDuXbwprn3uWriB036wvOWKIiItUKJvxoWf682ueTP56uQhACy5Ywq3TW2c2hk7KPeEj50/dxm/f/NjSipqAFhRsI8dxWUAXPPYm+TPXcaSYzxV0znH0o1F1Nd3vLMxEel4NHVznHYdKKdftwwyUpP50YsFbNl3hLW7Dp/w8d6aewnnzwvO49877Ux+seLDiO1v3nsxed2zeHHDXgb1yGLc4O787m87eWjZB5wzOJcXbj//pNojIv5wrKkbJfpWkj93WczyPl3T2X+0+qSOffbAbmzaWwrA0m9NYdajbwLQq0saB8pqWHLH+YzOy42IY9e8mQAU7C1l1qNvsvb+y+jdNf2k4hCRjkuJvh2UVQeoCdRT7xxzF29i1db9PH/7eYzOyw0l3+9PO4N/XbG11T4znRq+nLyKUpdNKV1I69KD7UdTKHHZjD59CG9sjzzT2DVvJoG6ek6//yUA/u36MTz55sfsOVzBpgevBKCu3rF6WzFVNXVMP7s/ACu3fEZVbR3VgXomDetBXvfGB8KVVQd49NVt3HP558hITW61tonI8VGi70CaG/mfiIEU81bGXc1uP+IyOUI2pS6bEteFUrKpSO7KgUBWsKxhG128ziKbUteFo2QCxtaHppGektxszLvmzeTbz27g+ff2MmpgDvdOO5OcjFQ27S3lpklDjhl79JlHS6pq6/j9mx9z+9TT8N5B3O6qautIT0lK2OeLHMuxEn1c74yV1vPeA5cz7qGVtEb/WkRPxlf9hlwroxvl5Fg5uZTTzcrJpYxuVk43b1s3K2c4e+nmyumWXEa6Nf/4hjpnlJLN4Xk5HAhk8cfULEpp7CwaOoUnfrONwk8CnGHZHNibzb/8vpgq0gAjPSWJ73nfIr5h4mCmntGbp9/9hOF9uvAvFw6L+LySihrG/mQli26dzIT8HhHbSitrefLNj/n9mx9TVh3g2bV7WP39i0/qz+3dnQcZnZdLSrKRmtz0foSq2jqqa+vplpUaKis8XMGUX7zOab2zefU7U0/4s6sDdaQmJZGk22alHWlEnwBVtXWs2XmQ//Wfa4HgqHbJ+0Xc+cx7ADx/+3l0TU/h8n9f3UYRODKooRvloU4i14IdQw7l5Fp5xLZuVk63ho6DcpKt+X8z1S6F0rAzhJKwM4XGssYO44hlU1IfXK8lhWV3TuHWP61n6R0X8PHBcq59/K1mP2tIzyxunpzPVyYOxiz41NGuGSkM6ZnNuzsPsmlvKV+/INipDLtvGfUO8rpnUni4MnSMWGcU1z7+Fhv2lLD8zgvYf7SK0spaHlr2AcXetZbofbZ+epQBuRks37SPf+wuoWtGCv8n7A1mb28/wMDumQzukRV6ZlL4MT4traJft4xj/YWJtEhTNx1UaWVt6CXlsRQfreb6+W9TVFrFJWf0YVjvbJ5YtYORA3JYcPOE0N0614wdQHl1gL9+sL/JMS76XG/e+Ki41WI26ulCVcSZQsPZQ8PZRA5lkZ2F14HkWOUxj13u0imhC0fCO4SwKaYjYZ1EhUunknQqSKcybDkQ4yR10a2Tua4V3zXwy+vH8MVxAzEzikoqOW/ea03qvPadi/j0SBXVtfXc8odgh37+6T15a/tBAH72hbOZPqoftz21njU7gy+8CU/+zjmG3recgbmZ/Oct51JZU8eYk7ilV/xPib4TaEgM4R694RyuGjOAxesLWf/JYf6x+zAffnqUZ+dMYkBuJhf86+tcMaIvr2z57Lg+64aJg3nm758cd4zJ1EWcMYSfKeSGnTHkWsM0VOO2DKuN6zNqXDJVXtKvcOkRy5WkU0mat5zhdRJpXieREbYc2Xk07ptOHa13wXnkgBw2Fx2JKLth4mB+/sWz2VhYwtWPRZ7NNHc942BZNV0zUklNtojrB0eqaslMTY45PSX+o0TfSRSVVPLBviNcelZfKmvqyEyLLyn9dctnbC46wtN/382a+y7FzI550fjDn07jzAdWhNa/dcnpPPra9pOO/1jSqQnrJMrIsmoyqSGTam+5ikxqvOXqsPJqsqgmM2LZ24+qY05DxVLtUkJJP/ysosqlURHqPLwOhXQqXUbYsteJhC0H920sr2/hO4wf/3wGZkagrp4650g2C91FFa7hDq8ZZ/fjiRvHA7B9/1EK9h7h7mc38IVzBvKrL49h7uJNPLtuDx89NJ20lMbPrg7U8eirwb/T7155RsSxwx/cJx2HEr0ct+Wb9nH7U//gnMG55GSkhqZ/tj08ndTkpIgR5655M1mz8yCzF6xhxtn9WL7pUwDuvHQ4Xzt/KGN+8kqT4/fNSeezI/F9v+B/nZdPj+w0vnXJ6U3OWk6OI51aMqghi2qyrCpsuWmHEblcQ5ZVxew8GperSTrujiQ11AE0dhgZVLh0yshkQN++fFRqFFakcZRMjrosjpLl/c7kiLdcRmbE2ces0f1ZunHfMT/78a+M45tP/6NJ+QOzRvC1KUOBxrul/n7/pfTp2nhdwTnHgbIaPjlUzvghkRfU6+odBroA3caU6OWkxbod8kBZNd0yU0NTAysK9jH1jD6M/vEr1ATqQ3VrAvU8/vp2rhufR5+cdNJTggloweod/Gz5hxF32zy4ZDNl1QEWrS/k3/9pDNNG9m9yZnKwrJrxD/21SYw/vnok89/Ywbgh3Vm2cR+vfuciLv3lGxF1XrnnQq7wLnLPPncQC9fuaY0/nmYEO5JYZxXNdx5Nz04aOqEuVJJjFXSlIq6prHKXHtEJNHQKR1xmWHkWRxvWvbIjYXUbOosnbhzHhj0lLFi9M3T8bQ9PZ/mmfVw5sh/ffe79UEfSPSuVt+ZewogfRr6voeHfw4GyanIyUklLSaK+3vHi+3u559n32fmzGSfcGZRU1FBVW9+pL2or0ctJqwnUk5Jkcf1HrKgJUO+gS/qx7951LvhEz/AvYMXrSFUtf167h69NGUpdvWt2KuFweQ07D5Tz29U7+c1N4zAzLvnlKnYfrGDHz2ZQWlnL3MUb+fHVI+mTkxHqfAB+/9UJnJ3XjYkPvwrA/JvGc9lZfXhufSH3PR98ON2dl5zOl88dRN+cDD4trWJQjyx++crWZqeylt05hf95fx/z39gRKvvyhDz+vK7wuNqfSoCuVNDVS/xdrZKc8HUqw7YF13PC6nalgkyrafFzKlx61JlD41lDRCfR0JmQxZGobbEukMfScJY3uEcWi287L+5vcj/17m7ufyH4tNk/f2MyE4f2aFJnz6EK8rpnhq5hlFUHKK8O0DensWMorw7w3Lo93Dw5v93OPgJ19SRZfP+vWnLSid7MpgH/F0gGfuecmxe1fSrwIvCxV/S8c+4n8ewbixK9JJpzLpQUqmrrWLV1P9NGBb8pHKirZ9SDL/OtS4bzzYtPb/YY//z7d/nbtgOh9TsuPj003x1+DST8eUfRFt92Hl0zUkJnIa0pJdRZBBN/TsxOojLUWeRErXelkixrefqt0qVFJP4jUWcY4Z1E8IwiWPfi0UNJSsvk1Y9KWXrPpZCcDinp4P29zF28kUC9Y9H6yE7yh7NGkJWWzOyJwceBP/76dh55ufEb6Q9/YVSoY1h823mMH9I9uN+LBfzXO7v58dUj+ep5+ZRU1JCblRZx7P1HqiirDjCsd5eIcuccj722nWvPGcigHlmhsv1HqyM6k5KKGpZu3MeNnx8ccS0s3i8OHstJJXozSwY+Ai4HCoG1wA3OuS1hdaYC33XOzTrefWNRohc/iXXx8m/birnj6ff4t+vHcPmIvlTV1vGX9/YyfVR/xvzkFfK6Z7L0W1NCiSbWXVUNnv6Xz7N04z5+9oWzAVi8vpDveC+2v/iM3ry+tfVur42WQoAuXseQE95BNOkUKsiJ6iQayrPj6CzCVbsUakilhhSqSaXGhS1769Wkcs7QvnTr2oXFG4updilUk0YNwX2rvX1qSOWaCcP409pPI46RkpbBoeok7rh8BJeMGszeo3XsLqnjjue2UEMKm356FdUuhQkPv8rCOZPYW1LJN/57Pb26pHOgLNiewT2y+ORQBcvunMLIAd2A4MuIDpXX8PhXxjFzdP8OlegnAw8656701u8DcM79PKzOVGIn+hb3jUWJXiS2z45UsWbnQa4ZO5C3dxzgQFkNV48ZEFGnqraOMx9YwQ9mnMmcC08LPdhu6bemMGpgt4iziTkXDuO+6Wdyyx/WsmprMdNG9uP+mWcBkJuVyq4DFVz12JtxxTZ2UC4b9pQcd5uSqQvrLBo7gWwqSbMA6dSSTi1pBEijlnSrJc1bT6eWNGvY7pVZY/10aoL7RZUd791Wzal2qVRHdDKxO5Q+PbpxxoBe/KXgQKismtSIjurmC87gYCCDsbNuPaFYTvYRCAOB8CtWhcDnY9SbbGbvA0UEk/7m49gXM5sDzAEYPLjlNzCJdEZ9czK4ZuxAAM47rVfMOhmpyREjxFEDu8UcMf7lm+eH3qvwh1smNtkOcHZecCQ6fkh3Hpg1ggHdMuiTk8HF/7aK2rp6crNSKdh7JHS86Ntyv3jOQG6behpDe2Xzq5UfccPEwazffZi7n90QqlNHsvdt6rDpkDa+dJhMXczOIj2qLC28kwnrUNK9DiXtGB1KQ6eUTSVJhw+x+/A2JiVFdUrUNt6ZtQbSXS5u5jda/XlK8ST6WJ8Y/dfwD2CIc67MzGYAfwGGx7lvsNC5BcACCI7o44hLRE7Ahz+dxoY9JXG/PGft/ZeRk5kSulsK4PXvTgWCU0oPL/uAmaP7R+zz0LWjGNY7m8nDeoaS1vennQnAoB5ZXHvOwIj643+6koPlwYvDu+bNbNWH/8VSRzKVJBP6rnasjNMuWciRQl2os0ihnjUOklv5WnA8ib4QGBS2nkdw1B7inDsStrzczJ4ws17x7Csi7SsjNZlJw3rGXf9Yd7+YWcRzfdbefxlPv/tJ6GJjvNY/cDnv7ylhQG4mAA9eNYIH/2cLK++5kOz0FKpq67gk6lbZBt0yg7dzPrVmN1PP6MOV/9H0wvVfv30Rdz/7Hvdc9jm+9seONC1sBEghQAoVBC/atsV7ouOZo08heEH1UmAvwQuqX/GmZhrq9AM+c845M5sILAKGELzT5pj7xqI5ehGJVl/vqHOO1OQkqmrrKK8O0LNL006otLKWZRv38YMXGt/PHD51VVRSydpdh7hyZL+Ib3h/dfIQDlfUhl7jecPEQbz24f6YX+zLSkvGgPKaulDZOYNzee+TktD64B5ZvPqdi3ho6Rb++M7uUPnwPl24eswAfrnyI0b0z+GbF58e8UW1E70w2xq3V84A/oNg4n7SOfewmd0K4Jybb2Z3ALcBAaAS+LZz7u3m9m3p85ToRaQ9HCqvIScjJXRX1JGqWkY/+AqzRvfnsa+Mo67ecfmv3uC/v/55MlOT+ePbu7j7suGhs5VD5TU88fp2fjDjLJKSYt8uWVlTx1k/XMGdlw5nzY6DPDNnUpNRe/hUVcISfXtToheRU9Ezfw++cyH6vQotKa8O8Lu/fcwdl5x+wlM3evGIiEg7uGHiid0xmJ2ewl2XDW/laBrpEXQiIj6nRC8i4nNK9CIiPqdELyLic0r0IiI+p0QvIuJzSvQiIj6nRC8i4nMd8puxZlYM7G6xYmy9gAMt1jq1dYY2gtrpJ52hjZDYdg5xzvWOtaFDJvqTYWbrmvsasF90hjaC2uknnaGN0HHbqakbERGfU6IXEfE5Pyb6BYkOoB10hjaC2uknnaGN0EHb6bs5ehERieTHEb2IiIRRohcR8TnfJHozm2ZmW81su5nNTXQ88TCzJ81sv5kVhJX1MLOVZrbN+909bNt9Xvu2mtmVYeXjzWyTt+3X5r3nzMzSzexZr/xdM8tv1wYGYxhkZq+b2QdmttnM7vJbO80sw8z+bmbve238sd/aGM7Mks3sPTNb6q37rp1mtsuLb4OZrfPKTt12OudO+R+C76PdAQwD0oD3gRGJjiuOuC8ExgEFYWX/Csz1lucCv/CWR3jtSgeGeu1N9rb9HZgMGPASMN0rvx2Y7y3PBp5NQBv7A+O85a4EXxY/wk/t9OLp4i2nAu8Ck/zUxqj2fht4Gljqx3+z3mfvAnpFlZ2y7UzIP5Q2+EuZDLwctn4fcF+i44oz9nwiE/1WoL+33B/YGqtNwMteu/sDH4aV3wD8v/A63nIKwW/sWYLb+yJwuV/bCWQB/wA+78c2AnnAq8AlNCZ6P7ZzF00T/SnbTr9M3QwE9oStF3plp6K+zrl9AN7vPl55c20c6C1Hl0fs45wLAKVAzzaLvAXe6ek5BEe8vmqnN52xAdgPrHTO+a6Nnv8Avg/Uh5X5sZ0OeMXM1pvZHK/slG2nX14OHuu16X67b7S5Nh6r7R3mz8XMugCLgbudc0e8qcqYVWOUdfh2OufqgLFmlgu8YGajjlH9lGyjmc0C9jvn1pvZ1Hh2iVHW4dvpOd85V2RmfYCVZvbhMep2+Hb6ZURfCAwKW88DihIUy8n6zMz6A3i/93vlzbWx0FuOLo/Yx8xSgG7AoTaLvBlmlkowyT/lnHveK/ZdOwGccyXAKmAa/mvj+cDVZrYLWAhcYmZ/wn/txDlX5P3eD7wATOQUbqdfEv1aYLiZDTWzNIIXN5YkOKYTtQT4qrf8VYJz2g3ls72r9UOB4cDfvVPIo2Y2ybuif3PUPg3Hug54zXmTgu3Fi+n3wAfOuV+FbfJNO82stzeSx8wygcuAD/FRGwGcc/c55/Kcc/kE/4+95py7CZ+108yyzaxrwzJwBVDAqdzO9r7I0YYXT2YQvKNjB3B/ouOJM+ZngH1ALcEe/msE5+leBbZ5v3uE1b/fa99WvKv3XvkEgv8QdwCP0fiN5wzgOWA7wav/wxLQxikET0k3Ahu8nxl+aicwGnjPa2MB8EOv3DdtjNHmqTRejPVVOwnevfe+97O5IZ+cyu3UIxBERHzOL1M3IiLSDCV6ERGfU6IXEfE5JXoREZ9TohcR8TklehERn1OiFxHxuf8P1EZJJP5zEw4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 79,
      "metadata": {
        "gather": {
          "logged": 1638240815164
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Execution time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "--- Execution time: 18652.234001874924 seconds ---\n"
        }
      ],
      "execution_count": 80,
      "metadata": {
        "gather": {
          "logged": 1638240815451
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "azureml_py38_pytorch",
      "language": "python",
      "display_name": "Python 3.8 - PyTorch"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "toc": {
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "336px"
      },
      "skip_h1_title": false,
      "number_sections": true,
      "title_cell": "Table of Contents",
      "toc_window_display": true,
      "base_numbering": 1,
      "toc_section_display": true,
      "title_sidebar": "Contents",
      "toc_cell": false,
      "nav_menu": {},
      "sideBar": true
    },
    "kernel_info": {
      "name": "azureml_py38_pytorch"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}